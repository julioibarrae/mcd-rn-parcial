{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "understanding-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sapphire-recording",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/healthcare-dataset-stroke-data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-camcorder",
   "metadata": {},
   "source": [
    "## Analisis del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-desktop",
   "metadata": {},
   "source": [
    "Describimos las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "healthy-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-atlas",
   "metadata": {},
   "source": [
    "Buscaremos valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binary-resort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-elite",
   "metadata": {},
   "source": [
    "Observamos que solamente la columna \"bmi\", cuenta con valores nulos, que representa alrededor del 4% por lo que eliminaremos esos valores, y verificamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radio-manner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-detail",
   "metadata": {},
   "source": [
    "Buscaremos valores unicos de cada columna no-numerica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unknown-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male' 'Female' 'Other']\n",
      "['Yes' 'No']\n",
      "['Private' 'Self-employed' 'Govt_job' 'children' 'Never_worked']\n",
      "['Urban' 'Rural']\n",
      "['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "print(df.gender.unique())\n",
    "print(df.ever_married.unique())\n",
    "print(df.work_type.unique())\n",
    "print(df.Residence_type.unique())\n",
    "print(df.smoking_status.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-diving",
   "metadata": {},
   "source": [
    "Analizamos la columna \"gender\" y observamos solamente 1 valor con \"Other\", por lo que eliminamos ese row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    2897\n",
       "Male      2011\n",
       "Other        1\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'] != \"Other\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-gothic",
   "metadata": {},
   "source": [
    "Cambiamos las columnas \"ever_married\" y \"Residence_type\" a 1 y 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "short-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ever_married = df.ever_married.map(dict(Yes=1, No=0))\n",
    "df.gender = df.gender.map(dict(Male=1, Female=0))\n",
    "df['residence_urban'] = df.Residence_type.map(dict(Urban=1, Rural=0))\n",
    "df = df.drop([\"Residence_type\"], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-panel",
   "metadata": {},
   "source": [
    "Realizamos el one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "particular-simulation",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'smoking_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-1aebc4dfc39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msmoking_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoking_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"smoke_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwork_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmoking_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"work_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoking_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwork_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstroke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stroke'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/redes/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'smoking_status'"
     ]
    }
   ],
   "source": [
    "smoking_cat = pd.get_dummies(df.smoking_status, \"smoke_\")\n",
    "work_cat = pd.get_dummies(df.smoking_status, \"work_\")\n",
    "df = pd.concat([df, smoking_cat,work_cat], axis=1)\n",
    "df['label'] = df.stroke\n",
    "df = df.drop('stroke', axis = 1)\n",
    "df = df.drop(\"id\",axis=1)\n",
    "df = df.drop(\"work_type\",axis=1)\n",
    "df = df.drop(\"smoking_status\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "worldwide-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>residence_urban</th>\n",
       "      <th>smoke__Unknown</th>\n",
       "      <th>smoke__formerly smoked</th>\n",
       "      <th>smoke__never smoked</th>\n",
       "      <th>smoke__smokes</th>\n",
       "      <th>work__Unknown</th>\n",
       "      <th>work__formerly smoked</th>\n",
       "      <th>work__never smoked</th>\n",
       "      <th>work__smokes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103.08</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4908 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  \\\n",
       "0          1  67.0             0              1             1   \n",
       "2          1  80.0             0              1             1   \n",
       "3          0  49.0             0              0             1   \n",
       "4          0  79.0             1              0             1   \n",
       "5          1  81.0             0              0             1   \n",
       "...      ...   ...           ...            ...           ...   \n",
       "5104       0  13.0             0              0             0   \n",
       "5106       0  81.0             0              0             1   \n",
       "5107       0  35.0             0              0             1   \n",
       "5108       1  51.0             0              0             1   \n",
       "5109       0  44.0             0              0             1   \n",
       "\n",
       "      avg_glucose_level   bmi  residence_urban  smoke__Unknown  \\\n",
       "0                228.69  36.6                1               0   \n",
       "2                105.92  32.5                0               0   \n",
       "3                171.23  34.4                1               0   \n",
       "4                174.12  24.0                0               0   \n",
       "5                186.21  29.0                1               0   \n",
       "...                 ...   ...              ...             ...   \n",
       "5104             103.08  18.6                0               1   \n",
       "5106             125.20  40.0                1               0   \n",
       "5107              82.99  30.6                0               0   \n",
       "5108             166.29  25.6                0               0   \n",
       "5109              85.28  26.2                1               1   \n",
       "\n",
       "      smoke__formerly smoked  smoke__never smoked  smoke__smokes  \\\n",
       "0                          1                    0              0   \n",
       "2                          0                    1              0   \n",
       "3                          0                    0              1   \n",
       "4                          0                    1              0   \n",
       "5                          1                    0              0   \n",
       "...                      ...                  ...            ...   \n",
       "5104                       0                    0              0   \n",
       "5106                       0                    1              0   \n",
       "5107                       0                    1              0   \n",
       "5108                       1                    0              0   \n",
       "5109                       0                    0              0   \n",
       "\n",
       "      work__Unknown  work__formerly smoked  work__never smoked  work__smokes  \\\n",
       "0                 0                      1                   0             0   \n",
       "2                 0                      0                   1             0   \n",
       "3                 0                      0                   0             1   \n",
       "4                 0                      0                   1             0   \n",
       "5                 0                      1                   0             0   \n",
       "...             ...                    ...                 ...           ...   \n",
       "5104              1                      0                   0             0   \n",
       "5106              0                      0                   1             0   \n",
       "5107              0                      0                   1             0   \n",
       "5108              0                      1                   0             0   \n",
       "5109              1                      0                   0             0   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "5         1  \n",
       "...     ...  \n",
       "5104      0  \n",
       "5106      0  \n",
       "5107      0  \n",
       "5108      0  \n",
       "5109      0  \n",
       "\n",
       "[4908 rows x 17 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-organization",
   "metadata": {},
   "source": [
    "## Separacion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-siemens",
   "metadata": {},
   "source": [
    "Separamos el dataset en las features (X_df) y la clasificación (y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distant-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df\n",
    "X_df = X_df.drop(['label'], axis=1)\n",
    "y_df = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-spectrum",
   "metadata": {},
   "source": [
    "Separamos la información en el dataset de entrenamiento y el dataset de prueba donde el 75% sera el dataset de entrenamiento y el 25% restante era de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "behind-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_ts, y_tr, y_ts = train_test_split(X_df, y_df, test_size = 0.25, random_state = 42)\n",
    "y_tr = np.asarray(y_tr, dtype = np.int)\n",
    "y_ts = np.asarray(y_ts, dtype = np.int)\n",
    "\n",
    "y_tr = np.reshape(y_tr, [3681,1])\n",
    "y_ts = np.reshape(y_ts, [1227,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "informal-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1227, 16)\n",
      "(3681, 16)\n",
      "(1227, 1)\n",
      "(3681, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_ts.shape)\n",
    "print(x_tr.shape)\n",
    "print(y_ts.shape)\n",
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-quick",
   "metadata": {},
   "source": [
    "Ahora, normalizaremos los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "double-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data : (3681, 16)\n",
      "Testing Data : (1227, 16)\n"
     ]
    }
   ],
   "source": [
    "# Training Data\n",
    "x_tr = MinMaxScaler().fit_transform(x_tr)\n",
    "print(\"Training Data :\", x_tr.shape)\n",
    "\n",
    "# Testing Data\n",
    "x_ts = MinMaxScaler().fit_transform(x_ts)\n",
    "print(\"Testing Data :\", x_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-mouse",
   "metadata": {},
   "source": [
    "## Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-jaguar",
   "metadata": {},
   "source": [
    "Definición de hyperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "portable-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "training_epochs = 500 # Total number of training epochs\n",
    "learning_rate = 0.001 # The learning rate\n",
    "momentum = 0.9 # Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-barbados",
   "metadata": {},
   "source": [
    "Definimos 3 modelos para comparar los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-hepatitis",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-spirituality",
   "metadata": {},
   "source": [
    "Función para creación de modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "functional-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model_1\n",
    "learning_rate = 0.001\n",
    "def create_model_1():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(16, input_dim=16,activation='sigmoid'))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile a model\n",
    "    model.compile(loss='binary_crossentropy',                  \n",
    "                  optimizer=tf.keras.optimizers.SGD(learning_rate, momentum),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-orange",
   "metadata": {},
   "source": [
    "Entrenamiento del modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "republican-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 289\n",
      "Trainable params: 289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3681 samples, validate on 1227 samples\n",
      "Epoch 1/500\n",
      "3681/3681 [==============================] - 0s 120us/sample - loss: 0.4039 - acc: 0.9158 - val_loss: 0.2643 - val_acc: 0.9487\n",
      "Epoch 2/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.2141 - acc: 0.9603 - val_loss: 0.2212 - val_acc: 0.9487\n",
      "Epoch 3/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1871 - acc: 0.9603 - val_loss: 0.2119 - val_acc: 0.9487\n",
      "Epoch 4/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1789 - acc: 0.9603 - val_loss: 0.2095 - val_acc: 0.9487\n",
      "Epoch 5/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1757 - acc: 0.9603 - val_loss: 0.2089 - val_acc: 0.9487\n",
      "Epoch 6/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1741 - acc: 0.9603 - val_loss: 0.2089 - val_acc: 0.9487\n",
      "Epoch 7/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1733 - acc: 0.9603 - val_loss: 0.2089 - val_acc: 0.9487\n",
      "Epoch 8/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1732 - acc: 0.9603 - val_loss: 0.2087 - val_acc: 0.9487\n",
      "Epoch 9/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1727 - acc: 0.9603 - val_loss: 0.2088 - val_acc: 0.9487\n",
      "Epoch 10/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1724 - acc: 0.9603 - val_loss: 0.2088 - val_acc: 0.9487\n",
      "Epoch 11/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1721 - acc: 0.9603 - val_loss: 0.2089 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1719 - acc: 0.9603 - val_loss: 0.2089 - val_acc: 0.9487\n",
      "Epoch 13/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1718 - acc: 0.9603 - val_loss: 0.2090 - val_acc: 0.9487\n",
      "Epoch 14/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1716 - acc: 0.9603 - val_loss: 0.2087 - val_acc: 0.9487\n",
      "Epoch 15/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1714 - acc: 0.9603 - val_loss: 0.2088 - val_acc: 0.9487\n",
      "Epoch 16/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1713 - acc: 0.9603 - val_loss: 0.2086 - val_acc: 0.9487\n",
      "Epoch 17/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1711 - acc: 0.9603 - val_loss: 0.2085 - val_acc: 0.9487\n",
      "Epoch 18/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1710 - acc: 0.9603 - val_loss: 0.2083 - val_acc: 0.9487\n",
      "Epoch 19/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1709 - acc: 0.9603 - val_loss: 0.2082 - val_acc: 0.9487\n",
      "Epoch 20/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1707 - acc: 0.9603 - val_loss: 0.2080 - val_acc: 0.9487\n",
      "Epoch 21/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1706 - acc: 0.9603 - val_loss: 0.2078 - val_acc: 0.9487\n",
      "Epoch 22/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1704 - acc: 0.9603 - val_loss: 0.2077 - val_acc: 0.9487\n",
      "Epoch 23/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1703 - acc: 0.9603 - val_loss: 0.2074 - val_acc: 0.9487\n",
      "Epoch 24/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1702 - acc: 0.9603 - val_loss: 0.2067 - val_acc: 0.9487\n",
      "Epoch 25/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1700 - acc: 0.9603 - val_loss: 0.2067 - val_acc: 0.9487\n",
      "Epoch 26/500\n",
      "3681/3681 [==============================] - 0s 95us/sample - loss: 0.1699 - acc: 0.9603 - val_loss: 0.2066 - val_acc: 0.9487\n",
      "Epoch 27/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1697 - acc: 0.9603 - val_loss: 0.2065 - val_acc: 0.9487\n",
      "Epoch 28/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1696 - acc: 0.9603 - val_loss: 0.2058 - val_acc: 0.9487\n",
      "Epoch 29/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1695 - acc: 0.9603 - val_loss: 0.2058 - val_acc: 0.9487\n",
      "Epoch 30/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1693 - acc: 0.9603 - val_loss: 0.2058 - val_acc: 0.9487\n",
      "Epoch 31/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1692 - acc: 0.9603 - val_loss: 0.2057 - val_acc: 0.9487\n",
      "Epoch 32/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1691 - acc: 0.9603 - val_loss: 0.2057 - val_acc: 0.9487\n",
      "Epoch 33/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1689 - acc: 0.9603 - val_loss: 0.2056 - val_acc: 0.9487\n",
      "Epoch 34/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1688 - acc: 0.9603 - val_loss: 0.2054 - val_acc: 0.9487\n",
      "Epoch 35/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1687 - acc: 0.9603 - val_loss: 0.2053 - val_acc: 0.9487\n",
      "Epoch 36/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1685 - acc: 0.9603 - val_loss: 0.2052 - val_acc: 0.9487\n",
      "Epoch 37/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1684 - acc: 0.9603 - val_loss: 0.2050 - val_acc: 0.9487\n",
      "Epoch 38/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1683 - acc: 0.9603 - val_loss: 0.2049 - val_acc: 0.9487\n",
      "Epoch 39/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1682 - acc: 0.9603 - val_loss: 0.2047 - val_acc: 0.9487\n",
      "Epoch 40/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1681 - acc: 0.9603 - val_loss: 0.2046 - val_acc: 0.9487\n",
      "Epoch 41/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1680 - acc: 0.9603 - val_loss: 0.2046 - val_acc: 0.9487\n",
      "Epoch 42/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1678 - acc: 0.9603 - val_loss: 0.2043 - val_acc: 0.9487\n",
      "Epoch 43/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1677 - acc: 0.9603 - val_loss: 0.2042 - val_acc: 0.9487\n",
      "Epoch 44/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1676 - acc: 0.9603 - val_loss: 0.2040 - val_acc: 0.9487\n",
      "Epoch 45/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1675 - acc: 0.9603 - val_loss: 0.2039 - val_acc: 0.9487\n",
      "Epoch 46/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1673 - acc: 0.9603 - val_loss: 0.2036 - val_acc: 0.9487\n",
      "Epoch 47/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1672 - acc: 0.9603 - val_loss: 0.2035 - val_acc: 0.9487\n",
      "Epoch 48/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1671 - acc: 0.9603 - val_loss: 0.2034 - val_acc: 0.9487\n",
      "Epoch 49/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.1670 - acc: 0.9603 - val_loss: 0.2027 - val_acc: 0.9487\n",
      "Epoch 50/500\n",
      "3681/3681 [==============================] - 0s 115us/sample - loss: 0.1669 - acc: 0.9603 - val_loss: 0.2026 - val_acc: 0.9487\n",
      "Epoch 51/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 0.1668 - acc: 0.9603 - val_loss: 0.2027 - val_acc: 0.9487\n",
      "Epoch 52/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1666 - acc: 0.9603 - val_loss: 0.2024 - val_acc: 0.9487\n",
      "Epoch 53/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1665 - acc: 0.9603 - val_loss: 0.2024 - val_acc: 0.9487\n",
      "Epoch 54/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1664 - acc: 0.9603 - val_loss: 0.2023 - val_acc: 0.9487\n",
      "Epoch 55/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1663 - acc: 0.9603 - val_loss: 0.2022 - val_acc: 0.9487\n",
      "Epoch 56/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1662 - acc: 0.9603 - val_loss: 0.2020 - val_acc: 0.9487\n",
      "Epoch 57/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1660 - acc: 0.9603 - val_loss: 0.2020 - val_acc: 0.9487\n",
      "Epoch 58/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1659 - acc: 0.9603 - val_loss: 0.2018 - val_acc: 0.9487\n",
      "Epoch 59/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1658 - acc: 0.9603 - val_loss: 0.2018 - val_acc: 0.9487\n",
      "Epoch 60/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1657 - acc: 0.9603 - val_loss: 0.2015 - val_acc: 0.9487\n",
      "Epoch 61/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1656 - acc: 0.9603 - val_loss: 0.2015 - val_acc: 0.9487\n",
      "Epoch 62/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 0.1655 - acc: 0.9603 - val_loss: 0.2012 - val_acc: 0.9487\n",
      "Epoch 63/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1654 - acc: 0.9603 - val_loss: 0.2012 - val_acc: 0.9487\n",
      "Epoch 64/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1653 - acc: 0.9603 - val_loss: 0.2010 - val_acc: 0.9487\n",
      "Epoch 65/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1652 - acc: 0.9603 - val_loss: 0.2008 - val_acc: 0.9487\n",
      "Epoch 66/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1651 - acc: 0.9603 - val_loss: 0.2007 - val_acc: 0.9487\n",
      "Epoch 67/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1649 - acc: 0.9603 - val_loss: 0.2006 - val_acc: 0.9487\n",
      "Epoch 68/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1648 - acc: 0.9603 - val_loss: 0.2004 - val_acc: 0.9487\n",
      "Epoch 69/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1647 - acc: 0.9603 - val_loss: 0.2003 - val_acc: 0.9487\n",
      "Epoch 70/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1646 - acc: 0.9603 - val_loss: 0.2002 - val_acc: 0.9487\n",
      "Epoch 71/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1645 - acc: 0.9603 - val_loss: 0.2001 - val_acc: 0.9487\n",
      "Epoch 72/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1644 - acc: 0.9603 - val_loss: 0.2000 - val_acc: 0.9487\n",
      "Epoch 73/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1643 - acc: 0.9603 - val_loss: 0.1999 - val_acc: 0.9487\n",
      "Epoch 74/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1642 - acc: 0.9603 - val_loss: 0.1996 - val_acc: 0.9487\n",
      "Epoch 75/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1641 - acc: 0.9603 - val_loss: 0.1995 - val_acc: 0.9487\n",
      "Epoch 76/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1640 - acc: 0.9603 - val_loss: 0.1989 - val_acc: 0.9487\n",
      "Epoch 77/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1639 - acc: 0.9603 - val_loss: 0.1989 - val_acc: 0.9487\n",
      "Epoch 78/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1638 - acc: 0.9603 - val_loss: 0.1989 - val_acc: 0.9487\n",
      "Epoch 79/500\n",
      "3681/3681 [==============================] - 0s 92us/sample - loss: 0.1637 - acc: 0.9603 - val_loss: 0.1988 - val_acc: 0.9487\n",
      "Epoch 80/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1636 - acc: 0.9603 - val_loss: 0.1988 - val_acc: 0.9487\n",
      "Epoch 81/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1635 - acc: 0.9603 - val_loss: 0.1986 - val_acc: 0.9487\n",
      "Epoch 82/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1634 - acc: 0.9603 - val_loss: 0.1986 - val_acc: 0.9487\n",
      "Epoch 83/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1633 - acc: 0.9603 - val_loss: 0.1984 - val_acc: 0.9487\n",
      "Epoch 84/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1632 - acc: 0.9603 - val_loss: 0.1983 - val_acc: 0.9487\n",
      "Epoch 85/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1631 - acc: 0.9603 - val_loss: 0.1982 - val_acc: 0.9487\n",
      "Epoch 86/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1630 - acc: 0.9603 - val_loss: 0.1980 - val_acc: 0.9487\n",
      "Epoch 87/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1629 - acc: 0.9603 - val_loss: 0.1979 - val_acc: 0.9487\n",
      "Epoch 88/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1628 - acc: 0.9603 - val_loss: 0.1978 - val_acc: 0.9487\n",
      "Epoch 89/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1627 - acc: 0.9603 - val_loss: 0.1978 - val_acc: 0.9487\n",
      "Epoch 90/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1626 - acc: 0.9603 - val_loss: 0.1975 - val_acc: 0.9487\n",
      "Epoch 91/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1624 - acc: 0.9603 - val_loss: 0.1975 - val_acc: 0.9487\n",
      "Epoch 92/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1624 - acc: 0.9603 - val_loss: 0.1974 - val_acc: 0.9487\n",
      "Epoch 93/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1623 - acc: 0.9603 - val_loss: 0.1972 - val_acc: 0.9487\n",
      "Epoch 94/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1622 - acc: 0.9603 - val_loss: 0.1970 - val_acc: 0.9487\n",
      "Epoch 95/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1621 - acc: 0.9603 - val_loss: 0.1970 - val_acc: 0.9487\n",
      "Epoch 96/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1620 - acc: 0.9603 - val_loss: 0.1968 - val_acc: 0.9487\n",
      "Epoch 97/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1619 - acc: 0.9603 - val_loss: 0.1967 - val_acc: 0.9487\n",
      "Epoch 98/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1618 - acc: 0.9603 - val_loss: 0.1965 - val_acc: 0.9487\n",
      "Epoch 99/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1617 - acc: 0.9603 - val_loss: 0.1964 - val_acc: 0.9487\n",
      "Epoch 100/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1616 - acc: 0.9603 - val_loss: 0.1963 - val_acc: 0.9487\n",
      "Epoch 101/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1615 - acc: 0.9603 - val_loss: 0.1962 - val_acc: 0.9487\n",
      "Epoch 102/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1614 - acc: 0.9603 - val_loss: 0.1961 - val_acc: 0.9487\n",
      "Epoch 103/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1613 - acc: 0.9603 - val_loss: 0.1959 - val_acc: 0.9487\n",
      "Epoch 104/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1612 - acc: 0.9603 - val_loss: 0.1958 - val_acc: 0.9487\n",
      "Epoch 105/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1611 - acc: 0.9603 - val_loss: 0.1957 - val_acc: 0.9487\n",
      "Epoch 106/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1610 - acc: 0.9603 - val_loss: 0.1950 - val_acc: 0.9487\n",
      "Epoch 107/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1609 - acc: 0.9603 - val_loss: 0.1949 - val_acc: 0.9487\n",
      "Epoch 108/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1608 - acc: 0.9603 - val_loss: 0.1949 - val_acc: 0.9487\n",
      "Epoch 109/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1607 - acc: 0.9603 - val_loss: 0.1949 - val_acc: 0.9487\n",
      "Epoch 110/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1606 - acc: 0.9603 - val_loss: 0.1947 - val_acc: 0.9487\n",
      "Epoch 111/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1605 - acc: 0.9603 - val_loss: 0.1948 - val_acc: 0.9487\n",
      "Epoch 112/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1604 - acc: 0.9603 - val_loss: 0.1948 - val_acc: 0.9487\n",
      "Epoch 113/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1603 - acc: 0.9603 - val_loss: 0.1946 - val_acc: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1602 - acc: 0.9603 - val_loss: 0.1945 - val_acc: 0.9487\n",
      "Epoch 115/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1601 - acc: 0.9603 - val_loss: 0.1943 - val_acc: 0.9487\n",
      "Epoch 116/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1601 - acc: 0.9603 - val_loss: 0.1942 - val_acc: 0.9487\n",
      "Epoch 117/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1600 - acc: 0.9603 - val_loss: 0.1941 - val_acc: 0.9487\n",
      "Epoch 118/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1599 - acc: 0.9603 - val_loss: 0.1942 - val_acc: 0.9487\n",
      "Epoch 119/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1598 - acc: 0.9603 - val_loss: 0.1940 - val_acc: 0.9487\n",
      "Epoch 120/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1597 - acc: 0.9603 - val_loss: 0.1939 - val_acc: 0.9487\n",
      "Epoch 121/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1596 - acc: 0.9603 - val_loss: 0.1938 - val_acc: 0.9487\n",
      "Epoch 122/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1595 - acc: 0.9603 - val_loss: 0.1936 - val_acc: 0.9487\n",
      "Epoch 123/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1594 - acc: 0.9603 - val_loss: 0.1935 - val_acc: 0.9487\n",
      "Epoch 124/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1593 - acc: 0.9603 - val_loss: 0.1933 - val_acc: 0.9487\n",
      "Epoch 125/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1592 - acc: 0.9603 - val_loss: 0.1933 - val_acc: 0.9487\n",
      "Epoch 126/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1592 - acc: 0.9603 - val_loss: 0.1932 - val_acc: 0.9487\n",
      "Epoch 127/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1591 - acc: 0.9603 - val_loss: 0.1930 - val_acc: 0.9487\n",
      "Epoch 128/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1590 - acc: 0.9603 - val_loss: 0.1930 - val_acc: 0.9487\n",
      "Epoch 129/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1589 - acc: 0.9603 - val_loss: 0.1927 - val_acc: 0.9487\n",
      "Epoch 130/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1588 - acc: 0.9603 - val_loss: 0.1927 - val_acc: 0.9487\n",
      "Epoch 131/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1587 - acc: 0.9603 - val_loss: 0.1926 - val_acc: 0.9487\n",
      "Epoch 132/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1587 - acc: 0.9603 - val_loss: 0.1925 - val_acc: 0.9487\n",
      "Epoch 133/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1586 - acc: 0.9603 - val_loss: 0.1924 - val_acc: 0.9487\n",
      "Epoch 134/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1585 - acc: 0.9603 - val_loss: 0.1923 - val_acc: 0.9487\n",
      "Epoch 135/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1584 - acc: 0.9603 - val_loss: 0.1921 - val_acc: 0.9487\n",
      "Epoch 136/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1583 - acc: 0.9603 - val_loss: 0.1920 - val_acc: 0.9487\n",
      "Epoch 137/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1582 - acc: 0.9603 - val_loss: 0.1919 - val_acc: 0.9487\n",
      "Epoch 138/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1582 - acc: 0.9603 - val_loss: 0.1919 - val_acc: 0.9487\n",
      "Epoch 139/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1581 - acc: 0.9603 - val_loss: 0.1917 - val_acc: 0.9487\n",
      "Epoch 140/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1580 - acc: 0.9603 - val_loss: 0.1916 - val_acc: 0.9487\n",
      "Epoch 141/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1579 - acc: 0.9603 - val_loss: 0.1915 - val_acc: 0.9487\n",
      "Epoch 142/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1578 - acc: 0.9603 - val_loss: 0.1914 - val_acc: 0.9487\n",
      "Epoch 143/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1577 - acc: 0.9603 - val_loss: 0.1913 - val_acc: 0.9487\n",
      "Epoch 144/500\n",
      "3681/3681 [==============================] - 0s 82us/sample - loss: 0.1577 - acc: 0.9603 - val_loss: 0.1911 - val_acc: 0.9487\n",
      "Epoch 145/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1576 - acc: 0.9603 - val_loss: 0.1911 - val_acc: 0.9487\n",
      "Epoch 146/500\n",
      "3681/3681 [==============================] - 0s 116us/sample - loss: 0.1575 - acc: 0.9603 - val_loss: 0.1909 - val_acc: 0.9487\n",
      "Epoch 147/500\n",
      "3681/3681 [==============================] - 0s 90us/sample - loss: 0.1574 - acc: 0.9603 - val_loss: 0.1908 - val_acc: 0.9487\n",
      "Epoch 148/500\n",
      "3681/3681 [==============================] - 0s 129us/sample - loss: 0.1573 - acc: 0.9603 - val_loss: 0.1908 - val_acc: 0.9487\n",
      "Epoch 149/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1573 - acc: 0.9603 - val_loss: 0.1908 - val_acc: 0.9487\n",
      "Epoch 150/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1572 - acc: 0.9603 - val_loss: 0.1906 - val_acc: 0.9487\n",
      "Epoch 151/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1571 - acc: 0.9603 - val_loss: 0.1904 - val_acc: 0.9487\n",
      "Epoch 152/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1570 - acc: 0.9603 - val_loss: 0.1903 - val_acc: 0.9487\n",
      "Epoch 153/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1569 - acc: 0.9603 - val_loss: 0.1903 - val_acc: 0.9487\n",
      "Epoch 154/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1569 - acc: 0.9603 - val_loss: 0.1900 - val_acc: 0.9487\n",
      "Epoch 155/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1568 - acc: 0.9603 - val_loss: 0.1900 - val_acc: 0.9487\n",
      "Epoch 156/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1567 - acc: 0.9603 - val_loss: 0.1899 - val_acc: 0.9487\n",
      "Epoch 157/500\n",
      "3681/3681 [==============================] - 0s 99us/sample - loss: 0.1566 - acc: 0.9603 - val_loss: 0.1898 - val_acc: 0.9487\n",
      "Epoch 158/500\n",
      "3681/3681 [==============================] - 0s 93us/sample - loss: 0.1565 - acc: 0.9603 - val_loss: 0.1898 - val_acc: 0.9487\n",
      "Epoch 159/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1565 - acc: 0.9603 - val_loss: 0.1895 - val_acc: 0.9487\n",
      "Epoch 160/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1564 - acc: 0.9603 - val_loss: 0.1895 - val_acc: 0.9487\n",
      "Epoch 161/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1563 - acc: 0.9603 - val_loss: 0.1894 - val_acc: 0.9487\n",
      "Epoch 162/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1562 - acc: 0.9603 - val_loss: 0.1893 - val_acc: 0.9487\n",
      "Epoch 163/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1562 - acc: 0.9603 - val_loss: 0.1892 - val_acc: 0.9487\n",
      "Epoch 164/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1561 - acc: 0.9603 - val_loss: 0.1891 - val_acc: 0.9487\n",
      "Epoch 165/500\n",
      "3681/3681 [==============================] - 0s 129us/sample - loss: 0.1560 - acc: 0.9603 - val_loss: 0.1890 - val_acc: 0.9487\n",
      "Epoch 166/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1559 - acc: 0.9603 - val_loss: 0.1889 - val_acc: 0.9487\n",
      "Epoch 167/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1559 - acc: 0.9603 - val_loss: 0.1887 - val_acc: 0.9487\n",
      "Epoch 168/500\n",
      "3681/3681 [==============================] - 1s 176us/sample - loss: 0.1558 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 169/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1557 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 170/500\n",
      "3681/3681 [==============================] - 1s 168us/sample - loss: 0.1556 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 171/500\n",
      "3681/3681 [==============================] - 0s 108us/sample - loss: 0.1555 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 172/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1555 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 173/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1554 - acc: 0.9603 - val_loss: 0.1880 - val_acc: 0.9487\n",
      "Epoch 174/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1553 - acc: 0.9603 - val_loss: 0.1879 - val_acc: 0.9487\n",
      "Epoch 175/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1553 - acc: 0.9603 - val_loss: 0.1878 - val_acc: 0.9487\n",
      "Epoch 176/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1553 - acc: 0.9603 - val_loss: 0.1873 - val_acc: 0.9487\n",
      "Epoch 177/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1551 - acc: 0.9603 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 178/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1551 - acc: 0.9603 - val_loss: 0.1873 - val_acc: 0.9487\n",
      "Epoch 179/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1550 - acc: 0.9603 - val_loss: 0.1873 - val_acc: 0.9487\n",
      "Epoch 180/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1549 - acc: 0.9603 - val_loss: 0.1873 - val_acc: 0.9487\n",
      "Epoch 181/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1548 - acc: 0.9603 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 182/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1548 - acc: 0.9603 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 183/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1547 - acc: 0.9603 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 184/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1546 - acc: 0.9603 - val_loss: 0.1872 - val_acc: 0.9487\n",
      "Epoch 185/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1546 - acc: 0.9603 - val_loss: 0.1870 - val_acc: 0.9487\n",
      "Epoch 186/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.1545 - acc: 0.9603 - val_loss: 0.1869 - val_acc: 0.9487\n",
      "Epoch 187/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1544 - acc: 0.9603 - val_loss: 0.1868 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1543 - acc: 0.9603 - val_loss: 0.1867 - val_acc: 0.9487\n",
      "Epoch 189/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1543 - acc: 0.9603 - val_loss: 0.1868 - val_acc: 0.9487\n",
      "Epoch 190/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1542 - acc: 0.9603 - val_loss: 0.1865 - val_acc: 0.9487\n",
      "Epoch 191/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1541 - acc: 0.9603 - val_loss: 0.1864 - val_acc: 0.9487\n",
      "Epoch 192/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1541 - acc: 0.9603 - val_loss: 0.1864 - val_acc: 0.9487\n",
      "Epoch 193/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1540 - acc: 0.9603 - val_loss: 0.1864 - val_acc: 0.9487\n",
      "Epoch 194/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1539 - acc: 0.9603 - val_loss: 0.1862 - val_acc: 0.9487\n",
      "Epoch 195/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1539 - acc: 0.9603 - val_loss: 0.1862 - val_acc: 0.9487\n",
      "Epoch 196/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1538 - acc: 0.9603 - val_loss: 0.1861 - val_acc: 0.9487\n",
      "Epoch 197/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1537 - acc: 0.9603 - val_loss: 0.1860 - val_acc: 0.9487\n",
      "Epoch 198/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1537 - acc: 0.9603 - val_loss: 0.1859 - val_acc: 0.9487\n",
      "Epoch 199/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1536 - acc: 0.9603 - val_loss: 0.1858 - val_acc: 0.9487\n",
      "Epoch 200/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1535 - acc: 0.9603 - val_loss: 0.1857 - val_acc: 0.9487\n",
      "Epoch 201/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1535 - acc: 0.9603 - val_loss: 0.1856 - val_acc: 0.9487\n",
      "Epoch 202/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1534 - acc: 0.9603 - val_loss: 0.1856 - val_acc: 0.9487\n",
      "Epoch 203/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1534 - acc: 0.9603 - val_loss: 0.1854 - val_acc: 0.9487\n",
      "Epoch 204/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1533 - acc: 0.9603 - val_loss: 0.1853 - val_acc: 0.9487\n",
      "Epoch 205/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1532 - acc: 0.9603 - val_loss: 0.1853 - val_acc: 0.9487\n",
      "Epoch 206/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1532 - acc: 0.9603 - val_loss: 0.1853 - val_acc: 0.9487\n",
      "Epoch 207/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1531 - acc: 0.9603 - val_loss: 0.1851 - val_acc: 0.9487\n",
      "Epoch 208/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1530 - acc: 0.9603 - val_loss: 0.1850 - val_acc: 0.9487\n",
      "Epoch 209/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1530 - acc: 0.9603 - val_loss: 0.1849 - val_acc: 0.9487\n",
      "Epoch 210/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1529 - acc: 0.9603 - val_loss: 0.1849 - val_acc: 0.9487\n",
      "Epoch 211/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1529 - acc: 0.9603 - val_loss: 0.1848 - val_acc: 0.9487\n",
      "Epoch 212/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1528 - acc: 0.9603 - val_loss: 0.1846 - val_acc: 0.9487\n",
      "Epoch 213/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1528 - acc: 0.9603 - val_loss: 0.1846 - val_acc: 0.9487\n",
      "Epoch 214/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1527 - acc: 0.9603 - val_loss: 0.1846 - val_acc: 0.9487\n",
      "Epoch 215/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1526 - acc: 0.9603 - val_loss: 0.1844 - val_acc: 0.9487\n",
      "Epoch 216/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1525 - acc: 0.9603 - val_loss: 0.1844 - val_acc: 0.9487\n",
      "Epoch 217/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1525 - acc: 0.9603 - val_loss: 0.1843 - val_acc: 0.9487\n",
      "Epoch 218/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1524 - acc: 0.9603 - val_loss: 0.1841 - val_acc: 0.9487\n",
      "Epoch 219/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1524 - acc: 0.9603 - val_loss: 0.1841 - val_acc: 0.9487\n",
      "Epoch 220/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1523 - acc: 0.9603 - val_loss: 0.1840 - val_acc: 0.9487\n",
      "Epoch 221/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1523 - acc: 0.9603 - val_loss: 0.1839 - val_acc: 0.9487\n",
      "Epoch 222/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1522 - acc: 0.9603 - val_loss: 0.1839 - val_acc: 0.9487\n",
      "Epoch 223/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1521 - acc: 0.9603 - val_loss: 0.1838 - val_acc: 0.9487\n",
      "Epoch 224/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1521 - acc: 0.9603 - val_loss: 0.1837 - val_acc: 0.9487\n",
      "Epoch 225/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1520 - acc: 0.9603 - val_loss: 0.1837 - val_acc: 0.9487\n",
      "Epoch 226/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1520 - acc: 0.9603 - val_loss: 0.1836 - val_acc: 0.9487\n",
      "Epoch 227/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1519 - acc: 0.9603 - val_loss: 0.1835 - val_acc: 0.9487\n",
      "Epoch 228/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1519 - acc: 0.9603 - val_loss: 0.1834 - val_acc: 0.9487\n",
      "Epoch 229/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1518 - acc: 0.9603 - val_loss: 0.1833 - val_acc: 0.9487\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1517 - acc: 0.9603 - val_loss: 0.1833 - val_acc: 0.9487\n",
      "Epoch 231/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1517 - acc: 0.9603 - val_loss: 0.1832 - val_acc: 0.9487\n",
      "Epoch 232/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1516 - acc: 0.9603 - val_loss: 0.1830 - val_acc: 0.9487\n",
      "Epoch 233/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1516 - acc: 0.9603 - val_loss: 0.1829 - val_acc: 0.9487\n",
      "Epoch 234/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1515 - acc: 0.9603 - val_loss: 0.1830 - val_acc: 0.9487\n",
      "Epoch 235/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1515 - acc: 0.9603 - val_loss: 0.1828 - val_acc: 0.9487\n",
      "Epoch 236/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1514 - acc: 0.9603 - val_loss: 0.1829 - val_acc: 0.9487\n",
      "Epoch 237/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1513 - acc: 0.9603 - val_loss: 0.1827 - val_acc: 0.9487\n",
      "Epoch 238/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1513 - acc: 0.9603 - val_loss: 0.1826 - val_acc: 0.9487\n",
      "Epoch 239/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1512 - acc: 0.9603 - val_loss: 0.1825 - val_acc: 0.9487\n",
      "Epoch 240/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1512 - acc: 0.9603 - val_loss: 0.1824 - val_acc: 0.9487\n",
      "Epoch 241/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1511 - acc: 0.9603 - val_loss: 0.1823 - val_acc: 0.9487\n",
      "Epoch 242/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1511 - acc: 0.9603 - val_loss: 0.1823 - val_acc: 0.9487\n",
      "Epoch 243/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1510 - acc: 0.9603 - val_loss: 0.1823 - val_acc: 0.9487\n",
      "Epoch 244/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1509 - acc: 0.9603 - val_loss: 0.1822 - val_acc: 0.9487\n",
      "Epoch 245/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1509 - acc: 0.9603 - val_loss: 0.1821 - val_acc: 0.9487\n",
      "Epoch 246/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1508 - acc: 0.9603 - val_loss: 0.1820 - val_acc: 0.9487\n",
      "Epoch 247/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1508 - acc: 0.9603 - val_loss: 0.1820 - val_acc: 0.9487\n",
      "Epoch 248/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1507 - acc: 0.9603 - val_loss: 0.1819 - val_acc: 0.9487\n",
      "Epoch 249/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1507 - acc: 0.9603 - val_loss: 0.1818 - val_acc: 0.9487\n",
      "Epoch 250/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1506 - acc: 0.9603 - val_loss: 0.1817 - val_acc: 0.9487\n",
      "Epoch 251/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1506 - acc: 0.9603 - val_loss: 0.1816 - val_acc: 0.9487\n",
      "Epoch 252/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1505 - acc: 0.9603 - val_loss: 0.1815 - val_acc: 0.9487\n",
      "Epoch 253/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1505 - acc: 0.9603 - val_loss: 0.1815 - val_acc: 0.9487\n",
      "Epoch 254/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1504 - acc: 0.9603 - val_loss: 0.1814 - val_acc: 0.9487\n",
      "Epoch 255/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1504 - acc: 0.9603 - val_loss: 0.1814 - val_acc: 0.9487\n",
      "Epoch 256/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1503 - acc: 0.9603 - val_loss: 0.1813 - val_acc: 0.9487\n",
      "Epoch 257/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1503 - acc: 0.9603 - val_loss: 0.1811 - val_acc: 0.9487\n",
      "Epoch 258/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1502 - acc: 0.9603 - val_loss: 0.1811 - val_acc: 0.9487\n",
      "Epoch 259/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1502 - acc: 0.9603 - val_loss: 0.1811 - val_acc: 0.9487\n",
      "Epoch 260/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1501 - acc: 0.9603 - val_loss: 0.1810 - val_acc: 0.9487\n",
      "Epoch 261/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1501 - acc: 0.9603 - val_loss: 0.1809 - val_acc: 0.9487\n",
      "Epoch 262/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1500 - acc: 0.9603 - val_loss: 0.1809 - val_acc: 0.9487\n",
      "Epoch 263/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1500 - acc: 0.9603 - val_loss: 0.1808 - val_acc: 0.9487\n",
      "Epoch 264/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1499 - acc: 0.9603 - val_loss: 0.1808 - val_acc: 0.9487\n",
      "Epoch 265/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1499 - acc: 0.9603 - val_loss: 0.1806 - val_acc: 0.9487\n",
      "Epoch 266/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1498 - acc: 0.9603 - val_loss: 0.1805 - val_acc: 0.9487\n",
      "Epoch 267/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1498 - acc: 0.9603 - val_loss: 0.1806 - val_acc: 0.9487\n",
      "Epoch 268/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1497 - acc: 0.9603 - val_loss: 0.1804 - val_acc: 0.9487\n",
      "Epoch 269/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1497 - acc: 0.9603 - val_loss: 0.1803 - val_acc: 0.9487\n",
      "Epoch 270/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1496 - acc: 0.9603 - val_loss: 0.1803 - val_acc: 0.9487\n",
      "Epoch 271/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1496 - acc: 0.9603 - val_loss: 0.1802 - val_acc: 0.9487\n",
      "Epoch 272/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1495 - acc: 0.9603 - val_loss: 0.1802 - val_acc: 0.9487\n",
      "Epoch 273/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1495 - acc: 0.9603 - val_loss: 0.1801 - val_acc: 0.9487\n",
      "Epoch 274/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1495 - acc: 0.9603 - val_loss: 0.1800 - val_acc: 0.9487\n",
      "Epoch 275/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1494 - acc: 0.9603 - val_loss: 0.1801 - val_acc: 0.9487\n",
      "Epoch 276/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1493 - acc: 0.9603 - val_loss: 0.1799 - val_acc: 0.9487\n",
      "Epoch 277/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1493 - acc: 0.9603 - val_loss: 0.1798 - val_acc: 0.9487\n",
      "Epoch 278/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1492 - acc: 0.9603 - val_loss: 0.1798 - val_acc: 0.9487\n",
      "Epoch 279/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1492 - acc: 0.9603 - val_loss: 0.1797 - val_acc: 0.9487\n",
      "Epoch 280/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1492 - acc: 0.9603 - val_loss: 0.1796 - val_acc: 0.9487\n",
      "Epoch 281/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1491 - acc: 0.9603 - val_loss: 0.1790 - val_acc: 0.9487\n",
      "Epoch 282/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1491 - acc: 0.9603 - val_loss: 0.1791 - val_acc: 0.9487\n",
      "Epoch 283/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1490 - acc: 0.9603 - val_loss: 0.1791 - val_acc: 0.9487\n",
      "Epoch 284/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1490 - acc: 0.9603 - val_loss: 0.1791 - val_acc: 0.9487\n",
      "Epoch 285/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1489 - acc: 0.9603 - val_loss: 0.1790 - val_acc: 0.9487\n",
      "Epoch 286/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1489 - acc: 0.9603 - val_loss: 0.1791 - val_acc: 0.9487\n",
      "Epoch 287/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1488 - acc: 0.9603 - val_loss: 0.1792 - val_acc: 0.9487\n",
      "Epoch 288/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1488 - acc: 0.9603 - val_loss: 0.1791 - val_acc: 0.9487\n",
      "Epoch 289/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1487 - acc: 0.9603 - val_loss: 0.1790 - val_acc: 0.9487\n",
      "Epoch 290/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1487 - acc: 0.9603 - val_loss: 0.1790 - val_acc: 0.9487\n",
      "Epoch 291/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1486 - acc: 0.9603 - val_loss: 0.1788 - val_acc: 0.9487\n",
      "Epoch 292/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1486 - acc: 0.9603 - val_loss: 0.1782 - val_acc: 0.9487\n",
      "Epoch 293/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1486 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 294/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1485 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 295/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1485 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 296/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1484 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 297/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1484 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 298/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1483 - acc: 0.9603 - val_loss: 0.1784 - val_acc: 0.9487\n",
      "Epoch 299/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1483 - acc: 0.9603 - val_loss: 0.1783 - val_acc: 0.9487\n",
      "Epoch 300/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1482 - acc: 0.9603 - val_loss: 0.1782 - val_acc: 0.9487\n",
      "Epoch 301/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1482 - acc: 0.9603 - val_loss: 0.1782 - val_acc: 0.9487\n",
      "Epoch 302/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1482 - acc: 0.9603 - val_loss: 0.1781 - val_acc: 0.9487\n",
      "Epoch 303/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1481 - acc: 0.9603 - val_loss: 0.1779 - val_acc: 0.9487\n",
      "Epoch 304/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1481 - acc: 0.9603 - val_loss: 0.1774 - val_acc: 0.9487\n",
      "Epoch 305/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1480 - acc: 0.9603 - val_loss: 0.1776 - val_acc: 0.9487\n",
      "Epoch 306/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1480 - acc: 0.9603 - val_loss: 0.1777 - val_acc: 0.9487\n",
      "Epoch 307/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1479 - acc: 0.9603 - val_loss: 0.1776 - val_acc: 0.9487\n",
      "Epoch 308/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1479 - acc: 0.9603 - val_loss: 0.1777 - val_acc: 0.9487\n",
      "Epoch 309/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1479 - acc: 0.9603 - val_loss: 0.1776 - val_acc: 0.9487\n",
      "Epoch 310/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1478 - acc: 0.9603 - val_loss: 0.1776 - val_acc: 0.9487\n",
      "Epoch 311/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1478 - acc: 0.9603 - val_loss: 0.1776 - val_acc: 0.9487\n",
      "Epoch 312/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1477 - acc: 0.9603 - val_loss: 0.1775 - val_acc: 0.9487\n",
      "Epoch 313/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1477 - acc: 0.9603 - val_loss: 0.1769 - val_acc: 0.9487\n",
      "Epoch 314/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1477 - acc: 0.9603 - val_loss: 0.1769 - val_acc: 0.9487\n",
      "Epoch 315/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1476 - acc: 0.9603 - val_loss: 0.1771 - val_acc: 0.9487\n",
      "Epoch 316/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1476 - acc: 0.9603 - val_loss: 0.1771 - val_acc: 0.9487\n",
      "Epoch 317/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1475 - acc: 0.9603 - val_loss: 0.1772 - val_acc: 0.9487\n",
      "Epoch 318/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1475 - acc: 0.9603 - val_loss: 0.1771 - val_acc: 0.9487\n",
      "Epoch 319/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1474 - acc: 0.9603 - val_loss: 0.1771 - val_acc: 0.9487\n",
      "Epoch 320/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1474 - acc: 0.9603 - val_loss: 0.1770 - val_acc: 0.9487\n",
      "Epoch 321/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1474 - acc: 0.9603 - val_loss: 0.1764 - val_acc: 0.9487\n",
      "Epoch 322/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1473 - acc: 0.9603 - val_loss: 0.1766 - val_acc: 0.9487\n",
      "Epoch 323/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1473 - acc: 0.9603 - val_loss: 0.1767 - val_acc: 0.9487\n",
      "Epoch 324/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1472 - acc: 0.9603 - val_loss: 0.1766 - val_acc: 0.9487\n",
      "Epoch 325/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1472 - acc: 0.9603 - val_loss: 0.1766 - val_acc: 0.9487\n",
      "Epoch 326/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1473 - acc: 0.9603 - val_loss: 0.1760 - val_acc: 0.9487\n",
      "Epoch 327/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1472 - acc: 0.9603 - val_loss: 0.1762 - val_acc: 0.9487\n",
      "Epoch 328/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1471 - acc: 0.9603 - val_loss: 0.1762 - val_acc: 0.9487\n",
      "Epoch 329/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1470 - acc: 0.9603 - val_loss: 0.1762 - val_acc: 0.9487\n",
      "Epoch 330/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1470 - acc: 0.9603 - val_loss: 0.1763 - val_acc: 0.9487\n",
      "Epoch 331/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1470 - acc: 0.9603 - val_loss: 0.1764 - val_acc: 0.9487\n",
      "Epoch 332/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1469 - acc: 0.9603 - val_loss: 0.1763 - val_acc: 0.9487\n",
      "Epoch 333/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1469 - acc: 0.9603 - val_loss: 0.1764 - val_acc: 0.9487\n",
      "Epoch 334/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1469 - acc: 0.9603 - val_loss: 0.1763 - val_acc: 0.9487\n",
      "Epoch 335/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1468 - acc: 0.9603 - val_loss: 0.1763 - val_acc: 0.9487\n",
      "Epoch 336/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1468 - acc: 0.9603 - val_loss: 0.1762 - val_acc: 0.9487\n",
      "Epoch 337/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1467 - acc: 0.9603 - val_loss: 0.1762 - val_acc: 0.9487\n",
      "Epoch 338/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1467 - acc: 0.9603 - val_loss: 0.1760 - val_acc: 0.9487\n",
      "Epoch 339/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1467 - acc: 0.9603 - val_loss: 0.1759 - val_acc: 0.9487\n",
      "Epoch 340/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1466 - acc: 0.9603 - val_loss: 0.1759 - val_acc: 0.9487\n",
      "Epoch 341/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1466 - acc: 0.9603 - val_loss: 0.1759 - val_acc: 0.9487\n",
      "Epoch 342/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1465 - acc: 0.9603 - val_loss: 0.1758 - val_acc: 0.9487\n",
      "Epoch 343/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1465 - acc: 0.9603 - val_loss: 0.1758 - val_acc: 0.9487\n",
      "Epoch 344/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1465 - acc: 0.9603 - val_loss: 0.1757 - val_acc: 0.9487\n",
      "Epoch 345/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1464 - acc: 0.9603 - val_loss: 0.1757 - val_acc: 0.9487\n",
      "Epoch 346/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1464 - acc: 0.9603 - val_loss: 0.1756 - val_acc: 0.9487\n",
      "Epoch 347/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1464 - acc: 0.9603 - val_loss: 0.1756 - val_acc: 0.9487\n",
      "Epoch 348/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1463 - acc: 0.9603 - val_loss: 0.1757 - val_acc: 0.9487\n",
      "Epoch 349/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1463 - acc: 0.9603 - val_loss: 0.1755 - val_acc: 0.9487\n",
      "Epoch 350/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1462 - acc: 0.9603 - val_loss: 0.1755 - val_acc: 0.9487\n",
      "Epoch 351/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1462 - acc: 0.9603 - val_loss: 0.1755 - val_acc: 0.9487\n",
      "Epoch 352/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1462 - acc: 0.9603 - val_loss: 0.1754 - val_acc: 0.9487\n",
      "Epoch 353/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1462 - acc: 0.9603 - val_loss: 0.1754 - val_acc: 0.9487\n",
      "Epoch 354/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1461 - acc: 0.9603 - val_loss: 0.1753 - val_acc: 0.9487\n",
      "Epoch 355/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1461 - acc: 0.9603 - val_loss: 0.1752 - val_acc: 0.9487\n",
      "Epoch 356/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1460 - acc: 0.9603 - val_loss: 0.1751 - val_acc: 0.9487\n",
      "Epoch 357/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1460 - acc: 0.9603 - val_loss: 0.1750 - val_acc: 0.9487\n",
      "Epoch 358/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1460 - acc: 0.9603 - val_loss: 0.1750 - val_acc: 0.9487\n",
      "Epoch 359/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1459 - acc: 0.9603 - val_loss: 0.1743 - val_acc: 0.9487\n",
      "Epoch 360/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1459 - acc: 0.9603 - val_loss: 0.1744 - val_acc: 0.9487\n",
      "Epoch 361/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1459 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.9487\n",
      "Epoch 362/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1458 - acc: 0.9603 - val_loss: 0.1746 - val_acc: 0.9487\n",
      "Epoch 363/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1458 - acc: 0.9603 - val_loss: 0.1746 - val_acc: 0.9487\n",
      "Epoch 364/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1457 - acc: 0.9603 - val_loss: 0.1746 - val_acc: 0.9487\n",
      "Epoch 365/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1457 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.9487\n",
      "Epoch 366/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1457 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.9487\n",
      "Epoch 367/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1456 - acc: 0.9603 - val_loss: 0.1746 - val_acc: 0.9487\n",
      "Epoch 368/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1456 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.9487\n",
      "Epoch 369/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1456 - acc: 0.9603 - val_loss: 0.1739 - val_acc: 0.9487\n",
      "Epoch 370/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1455 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 371/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1455 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 372/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1455 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 373/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1454 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 374/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1454 - acc: 0.9603 - val_loss: 0.1742 - val_acc: 0.9487\n",
      "Epoch 375/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1454 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 376/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1453 - acc: 0.9603 - val_loss: 0.1741 - val_acc: 0.9487\n",
      "Epoch 377/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1453 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 378/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1453 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 379/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1452 - acc: 0.9603 - val_loss: 0.1739 - val_acc: 0.9487\n",
      "Epoch 380/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1452 - acc: 0.9603 - val_loss: 0.1740 - val_acc: 0.9487\n",
      "Epoch 381/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1452 - acc: 0.9603 - val_loss: 0.1739 - val_acc: 0.9487\n",
      "Epoch 382/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1451 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 383/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1451 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 384/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1451 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 385/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1450 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 386/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1450 - acc: 0.9603 - val_loss: 0.1737 - val_acc: 0.9487\n",
      "Epoch 387/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1450 - acc: 0.9603 - val_loss: 0.1737 - val_acc: 0.9487\n",
      "Epoch 388/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1449 - acc: 0.9603 - val_loss: 0.1736 - val_acc: 0.9487\n",
      "Epoch 389/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1449 - acc: 0.9603 - val_loss: 0.1736 - val_acc: 0.9487\n",
      "Epoch 390/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1449 - acc: 0.9603 - val_loss: 0.1735 - val_acc: 0.9487\n",
      "Epoch 391/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1449 - acc: 0.9603 - val_loss: 0.1734 - val_acc: 0.9487\n",
      "Epoch 392/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1448 - acc: 0.9603 - val_loss: 0.1734 - val_acc: 0.9487\n",
      "Epoch 393/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1448 - acc: 0.9603 - val_loss: 0.1734 - val_acc: 0.9487\n",
      "Epoch 394/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1448 - acc: 0.9603 - val_loss: 0.1733 - val_acc: 0.9487\n",
      "Epoch 395/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1447 - acc: 0.9603 - val_loss: 0.1733 - val_acc: 0.9487\n",
      "Epoch 396/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1447 - acc: 0.9603 - val_loss: 0.1732 - val_acc: 0.9487\n",
      "Epoch 397/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1447 - acc: 0.9603 - val_loss: 0.1731 - val_acc: 0.9487\n",
      "Epoch 398/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1446 - acc: 0.9603 - val_loss: 0.1731 - val_acc: 0.9487\n",
      "Epoch 399/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1446 - acc: 0.9603 - val_loss: 0.1731 - val_acc: 0.9487\n",
      "Epoch 400/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1446 - acc: 0.9603 - val_loss: 0.1730 - val_acc: 0.9487\n",
      "Epoch 401/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1446 - acc: 0.9603 - val_loss: 0.1728 - val_acc: 0.9487\n",
      "Epoch 402/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1445 - acc: 0.9603 - val_loss: 0.1730 - val_acc: 0.9487\n",
      "Epoch 403/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1445 - acc: 0.9603 - val_loss: 0.1728 - val_acc: 0.9487\n",
      "Epoch 404/500\n",
      "3681/3681 [==============================] - 0s 93us/sample - loss: 0.1444 - acc: 0.9603 - val_loss: 0.1729 - val_acc: 0.9487\n",
      "Epoch 405/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1444 - acc: 0.9603 - val_loss: 0.1727 - val_acc: 0.9487\n",
      "Epoch 406/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1444 - acc: 0.9603 - val_loss: 0.1727 - val_acc: 0.9487\n",
      "Epoch 407/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1444 - acc: 0.9603 - val_loss: 0.1727 - val_acc: 0.9487\n",
      "Epoch 408/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1443 - acc: 0.9603 - val_loss: 0.1727 - val_acc: 0.9487\n",
      "Epoch 409/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1443 - acc: 0.9603 - val_loss: 0.1725 - val_acc: 0.9487\n",
      "Epoch 410/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1443 - acc: 0.9603 - val_loss: 0.1725 - val_acc: 0.9487\n",
      "Epoch 411/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1442 - acc: 0.9603 - val_loss: 0.1726 - val_acc: 0.9487\n",
      "Epoch 412/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1442 - acc: 0.9603 - val_loss: 0.1725 - val_acc: 0.9487\n",
      "Epoch 413/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1442 - acc: 0.9603 - val_loss: 0.1724 - val_acc: 0.9487\n",
      "Epoch 414/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1441 - acc: 0.9603 - val_loss: 0.1723 - val_acc: 0.9487\n",
      "Epoch 415/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1441 - acc: 0.9603 - val_loss: 0.1718 - val_acc: 0.9487\n",
      "Epoch 416/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1441 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 417/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1441 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 418/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1440 - acc: 0.9603 - val_loss: 0.1721 - val_acc: 0.9487\n",
      "Epoch 419/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1440 - acc: 0.9603 - val_loss: 0.1720 - val_acc: 0.9487\n",
      "Epoch 420/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1440 - acc: 0.9603 - val_loss: 0.1720 - val_acc: 0.9487\n",
      "Epoch 421/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1440 - acc: 0.9603 - val_loss: 0.1720 - val_acc: 0.9487\n",
      "Epoch 422/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1439 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 423/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1439 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 424/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1439 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 425/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1438 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 426/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1438 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 427/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1438 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 428/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1437 - acc: 0.9603 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 429/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1437 - acc: 0.9603 - val_loss: 0.1717 - val_acc: 0.9487\n",
      "Epoch 430/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1437 - acc: 0.9603 - val_loss: 0.1717 - val_acc: 0.9487\n",
      "Epoch 431/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1437 - acc: 0.9603 - val_loss: 0.1710 - val_acc: 0.9487\n",
      "Epoch 432/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1436 - acc: 0.9603 - val_loss: 0.1711 - val_acc: 0.9487\n",
      "Epoch 433/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1436 - acc: 0.9603 - val_loss: 0.1712 - val_acc: 0.9487\n",
      "Epoch 434/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1436 - acc: 0.9603 - val_loss: 0.1713 - val_acc: 0.9487\n",
      "Epoch 435/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1435 - acc: 0.9603 - val_loss: 0.1713 - val_acc: 0.9487\n",
      "Epoch 436/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1436 - acc: 0.9603 - val_loss: 0.1715 - val_acc: 0.9487\n",
      "Epoch 437/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1435 - acc: 0.9603 - val_loss: 0.1714 - val_acc: 0.9487\n",
      "Epoch 438/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1435 - acc: 0.9603 - val_loss: 0.1714 - val_acc: 0.9487\n",
      "Epoch 439/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1434 - acc: 0.9603 - val_loss: 0.1713 - val_acc: 0.9487\n",
      "Epoch 440/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1434 - acc: 0.9603 - val_loss: 0.1713 - val_acc: 0.9487\n",
      "Epoch 441/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1434 - acc: 0.9603 - val_loss: 0.1712 - val_acc: 0.9487\n",
      "Epoch 442/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1434 - acc: 0.9603 - val_loss: 0.1712 - val_acc: 0.9487\n",
      "Epoch 443/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1433 - acc: 0.9603 - val_loss: 0.1711 - val_acc: 0.9487\n",
      "Epoch 444/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1433 - acc: 0.9603 - val_loss: 0.1711 - val_acc: 0.9487\n",
      "Epoch 445/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1433 - acc: 0.9603 - val_loss: 0.1711 - val_acc: 0.9487\n",
      "Epoch 446/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1433 - acc: 0.9603 - val_loss: 0.1711 - val_acc: 0.9487\n",
      "Epoch 447/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1432 - acc: 0.9603 - val_loss: 0.1709 - val_acc: 0.9487\n",
      "Epoch 448/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1432 - acc: 0.9603 - val_loss: 0.1709 - val_acc: 0.9487\n",
      "Epoch 449/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1432 - acc: 0.9603 - val_loss: 0.1708 - val_acc: 0.9487\n",
      "Epoch 450/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1431 - acc: 0.9603 - val_loss: 0.1709 - val_acc: 0.9487\n",
      "Epoch 451/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1431 - acc: 0.9603 - val_loss: 0.1708 - val_acc: 0.9487\n",
      "Epoch 452/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1431 - acc: 0.9603 - val_loss: 0.1707 - val_acc: 0.9487\n",
      "Epoch 453/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1431 - acc: 0.9603 - val_loss: 0.1707 - val_acc: 0.9487\n",
      "Epoch 454/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1707 - val_acc: 0.9487\n",
      "Epoch 455/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1707 - val_acc: 0.9487\n",
      "Epoch 456/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1706 - val_acc: 0.9487\n",
      "Epoch 457/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1706 - val_acc: 0.9487\n",
      "Epoch 458/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1707 - val_acc: 0.9487\n",
      "Epoch 459/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1429 - acc: 0.9603 - val_loss: 0.1706 - val_acc: 0.9487\n",
      "Epoch 460/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1429 - acc: 0.9603 - val_loss: 0.1705 - val_acc: 0.9487\n",
      "Epoch 461/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1429 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 462/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1428 - acc: 0.9603 - val_loss: 0.1700 - val_acc: 0.9487\n",
      "Epoch 463/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1428 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9487\n",
      "Epoch 464/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1429 - acc: 0.9603 - val_loss: 0.1695 - val_acc: 0.9487\n",
      "Epoch 465/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1428 - acc: 0.9603 - val_loss: 0.1697 - val_acc: 0.9487\n",
      "Epoch 466/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1698 - val_acc: 0.9487\n",
      "Epoch 467/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 468/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1700 - val_acc: 0.9487\n",
      "Epoch 469/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9487\n",
      "Epoch 470/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1426 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9487\n",
      "Epoch 471/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1426 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9487\n",
      "Epoch 472/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1426 - acc: 0.9603 - val_loss: 0.1700 - val_acc: 0.9487\n",
      "Epoch 473/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1700 - val_acc: 0.9487\n",
      "Epoch 474/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1700 - val_acc: 0.9487\n",
      "Epoch 475/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1701 - val_acc: 0.9487\n",
      "Epoch 476/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 477/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 478/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1424 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 479/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1424 - acc: 0.9603 - val_loss: 0.1699 - val_acc: 0.9487\n",
      "Epoch 480/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1424 - acc: 0.9603 - val_loss: 0.1691 - val_acc: 0.9487\n",
      "Epoch 481/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1424 - acc: 0.9603 - val_loss: 0.1693 - val_acc: 0.9487\n",
      "Epoch 482/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1423 - acc: 0.9603 - val_loss: 0.1693 - val_acc: 0.9487\n",
      "Epoch 483/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1423 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 484/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1423 - acc: 0.9603 - val_loss: 0.1695 - val_acc: 0.9487\n",
      "Epoch 485/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1423 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 486/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1695 - val_acc: 0.9487\n",
      "Epoch 487/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1695 - val_acc: 0.9487\n",
      "Epoch 488/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 489/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 490/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1692 - val_acc: 0.9487\n",
      "Epoch 491/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1421 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 492/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1421 - acc: 0.9603 - val_loss: 0.1688 - val_acc: 0.9487\n",
      "Epoch 493/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1421 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 494/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1421 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 495/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1420 - acc: 0.9603 - val_loss: 0.1691 - val_acc: 0.9487\n",
      "Epoch 496/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1420 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n",
      "Epoch 497/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1420 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n",
      "Epoch 498/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1420 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n",
      "Epoch 499/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n",
      "Epoch 500/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_1 = create_model_1()\n",
    "model_1.summary()\n",
    "\n",
    "results_1 = model_1.fit(\n",
    "    x_tr, y_tr,\n",
    "    epochs= training_epochs,\n",
    "    validation_data = (x_ts, y_ts),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sitting-clause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Model 1 #######################\n",
      "\n",
      "\n",
      "Evaluating on training set...\n",
      "loss=0.1419, accuracy: 96.0337%\n",
      "Evaluating on testing set...\n",
      "loss=0.1690, accuracy: 94.8655%\n",
      "\n",
      "\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Loss : 0.4039\n",
      "\n",
      "Minimum Loss : 0.1419\n",
      "\n",
      "Loss difference : 0.2620\n"
     ]
    }
   ],
   "source": [
    "print(\"####################### Model 1 #######################\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss_1, accuracy_1) = model_1.evaluate(x_tr, y_tr, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_1,accuracy_1 * 100))\n",
    "\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss_1, accuracy_1) = model_1.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_1, accuracy_1 * 100))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"########################################################\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results_1.history['acc'])\n",
    "plt.plot(results_1.history['val_acc'])\n",
    "plt.title('model 1 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results_1.history['loss'])\n",
    "plt.plot(results_1.history['val_loss'])\n",
    "plt.title('model 1 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "max_loss_1 = np.max(results_1.history['loss'])\n",
    "min_loss_1 = np.min(results_1.history['loss'])\n",
    "print(\"Maximum Loss : {:.4f}\".format(max_loss_1))\n",
    "print(\"\")\n",
    "print(\"Minimum Loss : {:.4f}\".format(min_loss_1))\n",
    "print(\"\")\n",
    "print(\"Loss difference : {:.4f}\".format((max_loss_1 - min_loss_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-pendant",
   "metadata": {},
   "source": [
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-cargo",
   "metadata": {},
   "source": [
    "Creación de modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afraid-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "learning_rate = .001\n",
    "def create_model_2():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(16, input_dim=16,activation='sigmoid'))\n",
    "    \n",
    "    #model.add(tf.keras.layers.Dropout(0.2, input_shape=(16,)))\n",
    "    # Hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(16, input_dim=16,activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile a model\n",
    "    model.compile(loss='mean_squared_error',                  \n",
    "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-trial",
   "metadata": {},
   "source": [
    "Entrenamiento modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "seventh-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3681 samples, validate on 1227 samples\n",
      "Epoch 1/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 2/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 3/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 4/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 5/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 6/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 7/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 8/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 9/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 10/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 11/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 13/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 14/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 15/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 16/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 17/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 18/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 19/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 20/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 21/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 22/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 23/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 24/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 25/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 26/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 27/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 28/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 29/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 30/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 31/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 32/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 33/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 34/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 35/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 36/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 37/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 38/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 39/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 40/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 41/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 42/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 43/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 44/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 45/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 46/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 47/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 48/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 49/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 50/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 51/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 52/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 53/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 54/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 55/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 56/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 57/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 58/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 59/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 60/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 61/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 62/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 63/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 64/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 65/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 66/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 67/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 68/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 69/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 70/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 71/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 72/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 73/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 74/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 75/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 76/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 77/500\n",
      "3681/3681 [==============================] - 0s 91us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 78/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 79/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 80/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 81/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 82/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 83/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 84/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 85/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 86/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 87/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 88/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 89/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 90/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 91/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 92/500\n",
      "3681/3681 [==============================] - 0s 88us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 93/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 94/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 95/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 96/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 97/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 98/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 99/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 100/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 101/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 102/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 103/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 104/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 105/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 106/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 107/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 108/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 109/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 110/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 111/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 112/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 114/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 115/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 116/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 117/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 118/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 119/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 120/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 121/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 122/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 123/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 124/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 125/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 126/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 127/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 128/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 129/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 130/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 131/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 132/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 133/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 134/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 135/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 136/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 137/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 138/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 139/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 140/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 141/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 142/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 143/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 144/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 145/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 146/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 147/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 148/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 149/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 150/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 151/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 152/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 153/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 154/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 155/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 156/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 157/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 158/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 159/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 160/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 161/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 162/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 163/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 164/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 165/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 166/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 167/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 168/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 169/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 170/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 171/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 172/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 173/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 174/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 175/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 176/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 177/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 178/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 179/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 180/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 181/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 182/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 183/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 184/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 185/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 186/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 187/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 189/500\n",
      "3681/3681 [==============================] - 0s 84us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 190/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 191/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 192/500\n",
      "3681/3681 [==============================] - ETA: 0s - loss: 0.0407 - acc: 0.959 - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 193/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 194/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 195/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 196/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 197/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 198/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 199/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 200/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 201/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 202/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 203/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 204/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 205/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 206/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 207/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 208/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 209/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 210/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 211/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 212/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 213/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 214/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 215/500\n",
      "3681/3681 [==============================] - 0s 37us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 216/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 217/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 218/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 219/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 220/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 221/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 222/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 223/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 224/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 225/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 226/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 227/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 228/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 230/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 231/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 232/500\n",
      "3681/3681 [==============================] - 0s 82us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 233/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 234/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 235/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 236/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 237/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 238/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 239/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 240/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 241/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 242/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 243/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 244/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 245/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 246/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 247/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 248/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 249/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 250/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 251/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 252/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 253/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 254/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 255/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 256/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 257/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 258/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 259/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 260/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 261/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 262/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 263/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 264/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 265/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 266/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 267/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 268/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 269/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 270/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 271/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 272/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 273/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 274/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 275/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 276/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 277/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 278/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 279/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 280/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 281/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 282/500\n",
      "3681/3681 [==============================] - 0s 96us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 283/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 284/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 285/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 286/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 287/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 288/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 289/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 290/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 291/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 292/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 293/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 294/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 295/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 296/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 297/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 298/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 299/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 300/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 301/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 302/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 303/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 304/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 305/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 306/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 307/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 308/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 309/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 310/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 311/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 312/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 313/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 314/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 315/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 316/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 317/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 318/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 319/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 320/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 321/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 322/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 323/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 324/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 325/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 326/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 327/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 328/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 329/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 330/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 331/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 332/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 333/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 334/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 335/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 336/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 337/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 338/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 339/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 340/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 341/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 342/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 343/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 344/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 346/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 347/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 348/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 349/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 350/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 351/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 352/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 353/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 354/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 355/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 356/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 357/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 358/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 359/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 360/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 361/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 362/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 363/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 364/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 365/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 366/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 367/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 368/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 369/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 370/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 371/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 372/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 373/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 374/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 375/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 376/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 377/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 378/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 379/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 380/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 381/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 382/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 383/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 384/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 385/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 386/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 387/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 388/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 389/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 390/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 391/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 392/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 393/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 394/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 395/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 396/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 397/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 398/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 399/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 400/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 401/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 402/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 403/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 404/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 405/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 406/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 407/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 408/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 409/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 410/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 411/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 412/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 413/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 414/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 415/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 416/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 417/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 418/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 419/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 420/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 421/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 422/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 423/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 424/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 425/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 426/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 427/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 428/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 429/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 430/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 431/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 432/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 433/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 434/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 435/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 436/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 437/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 438/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 439/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 440/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 441/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 442/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 443/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 444/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 445/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 446/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 447/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 448/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 449/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 450/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 451/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 452/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 453/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 454/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 455/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 456/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 457/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 458/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 459/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 460/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 462/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 463/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 464/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 465/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 466/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 467/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 468/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 469/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 470/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 471/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 472/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 473/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 474/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 475/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 476/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 477/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 478/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 479/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 480/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 481/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 482/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 483/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 484/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 485/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 486/500\n",
      "3681/3681 [==============================] - 0s 39us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 487/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 488/500\n",
      "3681/3681 [==============================] - 0s 38us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 489/500\n",
      "3681/3681 [==============================] - 0s 40us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 490/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 491/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 492/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 493/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 494/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 495/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 496/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 497/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 498/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 499/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n",
      "Epoch 500/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.0397 - acc: 0.9603 - val_loss: 0.0513 - val_acc: 0.9487\n"
     ]
    }
   ],
   "source": [
    "model_2 = create_model_2()\n",
    "model_2.summary()\n",
    "\n",
    "results_2 = model_2.fit(\n",
    "    x_tr, y_tr,\n",
    "    epochs= training_epochs,\n",
    "    validation_data = (x_ts, y_ts),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "gentle-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Model 2 #######################\n",
      "\n",
      "\n",
      "Evaluating on training set...\n",
      "loss=0.0397, accuracy: 96.0337%\n",
      "Evaluating on testing set...\n",
      "loss=0.0513, accuracy: 94.8655%\n",
      "\n",
      "\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Loss : 0.0397\n",
      "\n",
      "Minimum Loss : 0.0397\n",
      "\n",
      "Loss difference : 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"####################### Model 2 #######################\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss_2, accuracy_2) = model_2.evaluate(x_tr, y_tr, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_2,accuracy_2 * 100))\n",
    "\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss_2, accuracy_2) = model_2.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_2,accuracy_2 * 100))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"########################################################\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results_2.history['acc'])\n",
    "plt.plot(results_2.history['val_acc'])\n",
    "plt.title('model 2 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results_2.history['loss'])\n",
    "plt.plot(results_2.history['val_loss'])\n",
    "plt.title('model 2 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "max_loss_2 = np.max(results_2.history['loss'])\n",
    "min_loss_2 = np.min(results_2.history['loss'])\n",
    "print(\"Maximum Loss : {:.4f}\".format(max_loss_2))\n",
    "print(\"\")\n",
    "print(\"Minimum Loss : {:.4f}\".format(min_loss_2))\n",
    "print(\"\")\n",
    "print(\"Loss difference : {:.4f}\".format((max_loss_2 - min_loss_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-africa",
   "metadata": {},
   "source": [
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-treatment",
   "metadata": {},
   "source": [
    "Creación modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "associate-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "learning_rate = .01\n",
    "def create_model_3():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(32, input_dim=16,activation='relu'))\n",
    "    # Hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(32, input_dim=32,activation='relu'))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile a model\n",
    "    model.compile(loss='binary_crossentropy',                  \n",
    "                  optimizer= tf.keras.optimizers.SGD(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-staff",
   "metadata": {},
   "source": [
    "Entrenamiento modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "furnished-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 31)                527       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                1024      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,584\n",
      "Trainable params: 1,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3681 samples, validate on 1227 samples\n",
      "Epoch 1/500\n",
      "3681/3681 [==============================] - 0s 113us/sample - loss: 0.4052 - acc: 0.9201 - val_loss: 0.2539 - val_acc: 0.9487\n",
      "Epoch 2/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.2028 - acc: 0.9603 - val_loss: 0.2100 - val_acc: 0.9487\n",
      "Epoch 3/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1780 - acc: 0.9603 - val_loss: 0.2060 - val_acc: 0.9487\n",
      "Epoch 4/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 0.1733 - acc: 0.9603 - val_loss: 0.2053 - val_acc: 0.9487\n",
      "Epoch 5/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1716 - acc: 0.9603 - val_loss: 0.2044 - val_acc: 0.9487\n",
      "Epoch 6/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1704 - acc: 0.9603 - val_loss: 0.2034 - val_acc: 0.9487\n",
      "Epoch 7/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1693 - acc: 0.9603 - val_loss: 0.2025 - val_acc: 0.9487\n",
      "Epoch 8/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1683 - acc: 0.9603 - val_loss: 0.2015 - val_acc: 0.9487\n",
      "Epoch 9/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1674 - acc: 0.9603 - val_loss: 0.2007 - val_acc: 0.9487\n",
      "Epoch 10/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1665 - acc: 0.9603 - val_loss: 0.1996 - val_acc: 0.9487\n",
      "Epoch 11/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1656 - acc: 0.9603 - val_loss: 0.1988 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1649 - acc: 0.9603 - val_loss: 0.1977 - val_acc: 0.9487\n",
      "Epoch 13/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1641 - acc: 0.9603 - val_loss: 0.1966 - val_acc: 0.9487\n",
      "Epoch 14/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1634 - acc: 0.9603 - val_loss: 0.1959 - val_acc: 0.9487\n",
      "Epoch 15/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1627 - acc: 0.9603 - val_loss: 0.1946 - val_acc: 0.9487\n",
      "Epoch 16/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1620 - acc: 0.9603 - val_loss: 0.1941 - val_acc: 0.9487\n",
      "Epoch 17/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1614 - acc: 0.9603 - val_loss: 0.1936 - val_acc: 0.9487\n",
      "Epoch 18/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1607 - acc: 0.9603 - val_loss: 0.1928 - val_acc: 0.9487\n",
      "Epoch 19/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1601 - acc: 0.9603 - val_loss: 0.1922 - val_acc: 0.9487\n",
      "Epoch 20/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1595 - acc: 0.9603 - val_loss: 0.1911 - val_acc: 0.9487\n",
      "Epoch 21/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1589 - acc: 0.9603 - val_loss: 0.1907 - val_acc: 0.9487\n",
      "Epoch 22/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1584 - acc: 0.9603 - val_loss: 0.1900 - val_acc: 0.9487\n",
      "Epoch 23/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1578 - acc: 0.9603 - val_loss: 0.1892 - val_acc: 0.9487\n",
      "Epoch 24/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1572 - acc: 0.9603 - val_loss: 0.1885 - val_acc: 0.9487\n",
      "Epoch 25/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1567 - acc: 0.9603 - val_loss: 0.1881 - val_acc: 0.9487\n",
      "Epoch 26/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1562 - acc: 0.9603 - val_loss: 0.1873 - val_acc: 0.9487\n",
      "Epoch 27/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1557 - acc: 0.9603 - val_loss: 0.1869 - val_acc: 0.9487\n",
      "Epoch 28/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1551 - acc: 0.9603 - val_loss: 0.1863 - val_acc: 0.9487\n",
      "Epoch 29/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1546 - acc: 0.9603 - val_loss: 0.1858 - val_acc: 0.9487\n",
      "Epoch 30/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1542 - acc: 0.9603 - val_loss: 0.1851 - val_acc: 0.9487\n",
      "Epoch 31/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1537 - acc: 0.9603 - val_loss: 0.1846 - val_acc: 0.9487\n",
      "Epoch 32/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1532 - acc: 0.9603 - val_loss: 0.1838 - val_acc: 0.9487\n",
      "Epoch 33/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1528 - acc: 0.9603 - val_loss: 0.1834 - val_acc: 0.9487\n",
      "Epoch 34/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1523 - acc: 0.9603 - val_loss: 0.1830 - val_acc: 0.9487\n",
      "Epoch 35/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1519 - acc: 0.9603 - val_loss: 0.1823 - val_acc: 0.9487\n",
      "Epoch 36/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1514 - acc: 0.9603 - val_loss: 0.1818 - val_acc: 0.9487\n",
      "Epoch 37/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1510 - acc: 0.9603 - val_loss: 0.1814 - val_acc: 0.9487\n",
      "Epoch 38/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1506 - acc: 0.9603 - val_loss: 0.1810 - val_acc: 0.9487\n",
      "Epoch 39/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1502 - acc: 0.9603 - val_loss: 0.1805 - val_acc: 0.9487\n",
      "Epoch 40/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1498 - acc: 0.9603 - val_loss: 0.1795 - val_acc: 0.9487\n",
      "Epoch 41/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1494 - acc: 0.9603 - val_loss: 0.1794 - val_acc: 0.9487\n",
      "Epoch 42/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1490 - acc: 0.9603 - val_loss: 0.1787 - val_acc: 0.9487\n",
      "Epoch 43/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1487 - acc: 0.9603 - val_loss: 0.1785 - val_acc: 0.9487\n",
      "Epoch 44/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1483 - acc: 0.9603 - val_loss: 0.1779 - val_acc: 0.9487\n",
      "Epoch 45/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1479 - acc: 0.9603 - val_loss: 0.1779 - val_acc: 0.9487\n",
      "Epoch 46/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1475 - acc: 0.9603 - val_loss: 0.1770 - val_acc: 0.9487\n",
      "Epoch 47/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1472 - acc: 0.9603 - val_loss: 0.1766 - val_acc: 0.9487\n",
      "Epoch 48/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1468 - acc: 0.9603 - val_loss: 0.1761 - val_acc: 0.9487\n",
      "Epoch 49/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1465 - acc: 0.9603 - val_loss: 0.1761 - val_acc: 0.9487\n",
      "Epoch 50/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1462 - acc: 0.9603 - val_loss: 0.1759 - val_acc: 0.9487\n",
      "Epoch 51/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1458 - acc: 0.9603 - val_loss: 0.1749 - val_acc: 0.9487\n",
      "Epoch 52/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1455 - acc: 0.9603 - val_loss: 0.1744 - val_acc: 0.9487\n",
      "Epoch 53/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1452 - acc: 0.9603 - val_loss: 0.1739 - val_acc: 0.9487\n",
      "Epoch 54/500\n",
      "3681/3681 [==============================] - 0s 107us/sample - loss: 0.1449 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 55/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1447 - acc: 0.9603 - val_loss: 0.1738 - val_acc: 0.9487\n",
      "Epoch 56/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1444 - acc: 0.9603 - val_loss: 0.1731 - val_acc: 0.9487\n",
      "Epoch 57/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1441 - acc: 0.9603 - val_loss: 0.1728 - val_acc: 0.9487\n",
      "Epoch 58/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1438 - acc: 0.9603 - val_loss: 0.1732 - val_acc: 0.9487\n",
      "Epoch 59/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1435 - acc: 0.9603 - val_loss: 0.1726 - val_acc: 0.9487\n",
      "Epoch 60/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1433 - acc: 0.9603 - val_loss: 0.1725 - val_acc: 0.9487\n",
      "Epoch 61/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1430 - acc: 0.9603 - val_loss: 0.1718 - val_acc: 0.9487\n",
      "Epoch 62/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1723 - val_acc: 0.9487\n",
      "Epoch 63/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1425 - acc: 0.9603 - val_loss: 0.1717 - val_acc: 0.9487\n",
      "Epoch 64/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1422 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 65/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1427 - acc: 0.9603 - val_loss: 0.1698 - val_acc: 0.9487\n",
      "Epoch 66/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1708 - val_acc: 0.9487\n",
      "Epoch 67/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1416 - acc: 0.9603 - val_loss: 0.1709 - val_acc: 0.9487\n",
      "Epoch 68/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1414 - acc: 0.9603 - val_loss: 0.1713 - val_acc: 0.9487\n",
      "Epoch 69/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1709 - val_acc: 0.9487\n",
      "Epoch 70/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1704 - val_acc: 0.9487\n",
      "Epoch 71/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 72/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1691 - val_acc: 0.9487\n",
      "Epoch 73/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1692 - val_acc: 0.9487\n",
      "Epoch 74/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1696 - val_acc: 0.9487\n",
      "Epoch 75/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1694 - val_acc: 0.9487\n",
      "Epoch 76/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1398 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 77/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 78/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 79/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 80/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1688 - val_acc: 0.9487\n",
      "Epoch 81/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1691 - val_acc: 0.9487\n",
      "Epoch 82/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1387 - acc: 0.9603 - val_loss: 0.1683 - val_acc: 0.9487\n",
      "Epoch 83/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1682 - val_acc: 0.9487\n",
      "Epoch 84/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1680 - val_acc: 0.9487\n",
      "Epoch 85/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 86/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1667 - val_acc: 0.9487\n",
      "Epoch 87/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1676 - val_acc: 0.9487\n",
      "Epoch 88/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 89/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 90/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9487\n",
      "Epoch 91/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 92/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 93/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 94/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.9487\n",
      "Epoch 95/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1659 - val_acc: 0.9487\n",
      "Epoch 96/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.9487\n",
      "Epoch 97/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 98/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 99/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 100/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 101/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1358 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 102/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1358 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 103/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1356 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 104/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1355 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 105/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 106/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 107/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1353 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 108/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1351 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 109/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1349 - acc: 0.9603 - val_loss: 0.1667 - val_acc: 0.9487\n",
      "Epoch 110/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1350 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 111/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1348 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 112/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1347 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1346 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 114/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1345 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 115/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1343 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 116/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1343 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 117/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1342 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 118/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1341 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 119/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1340 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 120/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1340 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 121/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1339 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 122/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1337 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 123/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1337 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 124/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1336 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 125/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1335 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 126/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1335 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 127/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1334 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 128/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1333 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 129/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1332 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 130/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1332 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 131/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1331 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 132/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1331 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 133/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1330 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 134/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1329 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 135/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1328 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 136/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1327 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 137/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1327 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 138/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1327 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 139/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1326 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 140/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1326 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 141/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1325 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 142/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1324 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 143/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1324 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 144/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1324 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 145/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1323 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 146/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1322 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 147/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1322 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 148/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1321 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 149/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 150/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1319 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 151/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 152/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 153/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1319 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 154/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1320 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 155/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1317 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 156/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1317 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 157/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1316 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 158/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1316 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 159/500\n",
      "3681/3681 [==============================] - 0s 96us/sample - loss: 0.1317 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 160/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1315 - acc: 0.9603 - val_loss: 0.1592 - val_acc: 0.9487\n",
      "Epoch 161/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1331 - acc: 0.9603 - val_loss: 0.1600 - val_acc: 0.9487\n",
      "Epoch 162/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1332 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 163/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1316 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 164/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1315 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 165/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1315 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 166/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1315 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 167/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1314 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 168/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1313 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 169/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1313 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 170/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1314 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 171/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1314 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 172/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1312 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 173/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1312 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 174/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1312 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 175/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1311 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 176/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1312 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 177/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1310 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 178/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1310 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 179/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1310 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 180/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 181/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 182/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1310 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 183/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 184/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 185/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1308 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 186/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 187/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1309 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1308 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 189/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1308 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 190/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1307 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 191/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1308 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 192/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1307 - acc: 0.9603 - val_loss: 0.1586 - val_acc: 0.9487\n",
      "Epoch 193/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1313 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 194/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1307 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 195/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1306 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 196/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1307 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 197/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1306 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 198/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1305 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 199/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1306 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 200/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1306 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 201/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1305 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 202/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1304 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 203/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1305 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 204/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1304 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 205/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1304 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 206/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1304 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 207/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 208/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1303 - acc: 0.9603 - val_loss: 0.1614 - val_acc: 0.9487\n",
      "Epoch 209/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1303 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 210/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1303 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 211/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1304 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 212/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 213/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 214/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 215/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 216/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1303 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 217/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1302 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 218/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1301 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 219/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1301 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 220/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1301 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 221/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1301 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 222/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 223/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 224/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1301 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 225/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 226/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 227/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 228/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 230/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 231/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 232/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 233/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1298 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 234/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 235/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1298 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 236/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 237/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1300 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 238/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1298 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 239/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1298 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 240/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 241/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1299 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 242/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 243/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 244/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 245/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 246/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 247/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 248/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 249/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 250/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1295 - acc: 0.9603 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 251/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 252/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 253/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1297 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 254/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1295 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 255/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 256/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 257/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 258/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 259/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1296 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 260/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 261/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 262/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 263/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 264/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 265/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 266/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 267/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 268/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 269/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 270/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1291 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 271/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9495\n",
      "Epoch 272/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1308 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 273/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 274/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1294 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 275/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 276/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 277/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1292 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 278/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 279/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1293 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 280/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1292 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 281/500\n",
      "3681/3681 [==============================] - ETA: 0s - loss: 0.1292 - acc: 0.960 - 0s 54us/sample - loss: 0.1292 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 282/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1291 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 283/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 284/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 285/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1291 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 286/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1288 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 287/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1288 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 288/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 289/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 290/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1291 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 291/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 292/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 293/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 294/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 295/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 296/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1291 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 297/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 298/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 299/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 300/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1664 - val_acc: 0.9487\n",
      "Epoch 301/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 302/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 303/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 304/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1288 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 305/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1288 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 306/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1666 - val_acc: 0.9487\n",
      "Epoch 307/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1289 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 308/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 309/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 310/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1286 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 311/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 312/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1286 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 313/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 314/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 315/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1663 - val_acc: 0.9487\n",
      "Epoch 316/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1670 - val_acc: 0.9487\n",
      "Epoch 317/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 318/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1287 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 319/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 320/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 321/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 322/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 323/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 324/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 325/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1660 - val_acc: 0.9487\n",
      "Epoch 326/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1285 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 327/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 328/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 329/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1295 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 330/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1286 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 331/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 332/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1282 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 333/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 334/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 335/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 336/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1282 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 337/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1284 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 338/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 339/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1282 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 340/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1282 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 341/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 342/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 343/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 344/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 345/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 346/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 347/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 348/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1282 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 349/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 350/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 351/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 352/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 353/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 354/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1279 - acc: 0.9603 - val_loss: 0.1614 - val_acc: 0.9487\n",
      "Epoch 355/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1290 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 356/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 357/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 358/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 359/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1279 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 360/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9495\n",
      "Epoch 361/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1299 - acc: 0.9606 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 362/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 363/500\n",
      "3681/3681 [==============================] - 0s 84us/sample - loss: 0.1279 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 364/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1279 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 365/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1279 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 366/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 367/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 368/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1659 - val_acc: 0.9487\n",
      "Epoch 369/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 370/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 371/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 372/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 373/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9478\n",
      "Epoch 374/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1297 - acc: 0.9598 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 375/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 376/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1280 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 377/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 378/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 379/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 380/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 381/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 382/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 383/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 384/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 385/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 386/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 387/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 388/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 389/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 390/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 391/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 392/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 393/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1283 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 394/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 395/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 396/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 397/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1697 - val_acc: 0.9487\n",
      "Epoch 398/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 399/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 400/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 401/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 402/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 403/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 404/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1275 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 405/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 406/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 407/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 408/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 409/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 410/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 411/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 412/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 413/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 414/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 415/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 416/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 417/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1687 - val_acc: 0.9487\n",
      "Epoch 418/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1299 - acc: 0.9609 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 419/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1274 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 420/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1274 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 421/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 422/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 423/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1272 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 424/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 425/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 426/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 427/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 428/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1277 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 429/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1273 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 430/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 431/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1664 - val_acc: 0.9487\n",
      "Epoch 432/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 433/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 434/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 435/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 436/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 437/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 438/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 439/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 440/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1669 - val_acc: 0.9487\n",
      "Epoch 441/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 442/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 0.1271 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9503\n",
      "Epoch 443/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1278 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 444/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 445/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 446/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9495\n",
      "Epoch 447/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1281 - acc: 0.9601 - val_loss: 0.1691 - val_acc: 0.9487\n",
      "Epoch 448/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1276 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 449/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 450/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1659 - val_acc: 0.9478\n",
      "Epoch 451/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1288 - acc: 0.9606 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 452/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 453/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1659 - val_acc: 0.9487\n",
      "Epoch 454/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 455/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1278 - acc: 0.9606 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 456/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 457/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1269 - acc: 0.9606 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 458/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 459/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 460/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 461/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 462/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1269 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 463/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 464/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 465/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 466/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 467/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 468/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 469/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1268 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 470/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 471/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1266 - acc: 0.9606 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 472/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1267 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 473/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 474/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 475/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1660 - val_acc: 0.9487\n",
      "Epoch 476/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1667 - val_acc: 0.9487\n",
      "Epoch 477/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 478/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1660 - val_acc: 0.9487\n",
      "Epoch 479/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 480/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 481/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1266 - acc: 0.9603 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 482/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 483/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 484/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1649 - val_acc: 0.9487\n",
      "Epoch 485/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1264 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 486/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1263 - acc: 0.9606 - val_loss: 0.1675 - val_acc: 0.9487\n",
      "Epoch 487/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1263 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 488/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1264 - acc: 0.9606 - val_loss: 0.1675 - val_acc: 0.9487\n",
      "Epoch 489/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1264 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 490/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1264 - acc: 0.9603 - val_loss: 0.1659 - val_acc: 0.9487\n",
      "Epoch 491/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1265 - acc: 0.9606 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 492/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1263 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 493/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1265 - acc: 0.9603 - val_loss: 0.1662 - val_acc: 0.9487\n",
      "Epoch 494/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1264 - acc: 0.9603 - val_loss: 0.1664 - val_acc: 0.9487\n",
      "Epoch 495/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1263 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9495\n",
      "Epoch 496/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1279 - acc: 0.9609 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 497/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1266 - acc: 0.9606 - val_loss: 0.1676 - val_acc: 0.9487\n",
      "Epoch 498/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1265 - acc: 0.9606 - val_loss: 0.1660 - val_acc: 0.9487\n",
      "Epoch 499/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1263 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 500/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1260 - acc: 0.9606 - val_loss: 0.1649 - val_acc: 0.9487\n"
     ]
    }
   ],
   "source": [
    "model_3 = create_model_3()\n",
    "model_3.summary()\n",
    "\n",
    "results_3 = model_3.fit(\n",
    "    x_tr, y_tr,\n",
    "    epochs= training_epochs,\n",
    "    validation_data = (x_ts, y_ts),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "other-checkout",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Model 3 #######################\n",
      "\n",
      "\n",
      "Evaluating on training set...\n",
      "loss=0.1258, accuracy: 96.0609%\n",
      "Evaluating on testing set...\n",
      "loss=0.1649, accuracy: 94.8655%\n",
      "\n",
      "\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Loss : 0.4052\n",
      "\n",
      "Minimum Loss : 0.1260\n",
      "\n",
      "Loss difference : 0.2792\n"
     ]
    }
   ],
   "source": [
    "print(\"####################### Model 3 #######################\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss_3, accuracy_3) = model_3.evaluate(x_tr, y_tr, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_3,accuracy_3 * 100))\n",
    "\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss_3, accuracy_3) = model_3.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_3,accuracy_3 * 100))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"########################################################\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results_3.history['acc'])\n",
    "plt.plot(results_3.history['val_acc'])\n",
    "plt.title('model 3 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results_3.history['loss'])\n",
    "plt.plot(results_3.history['val_loss'])\n",
    "plt.title('model 3 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "max_loss_3 = np.max(results_3.history['loss'])\n",
    "min_loss_3 = np.min(results_3.history['loss'])\n",
    "print(\"Maximum Loss : {:.4f}\".format(max_loss_3))\n",
    "print(\"\")\n",
    "print(\"Minimum Loss : {:.4f}\".format(min_loss_3))\n",
    "print(\"\")\n",
    "print(\"Loss difference : {:.4f}\".format((max_loss_3 - min_loss_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-brand",
   "metadata": {},
   "source": [
    "### Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "occupied-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "def create_model_4():\n",
    "    model = tf.keras.Sequential()\n",
    "    # Hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(16, input_dim=16,activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.2, input_shape=(16,)))\n",
    "    # Hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(8, input_dim=16,activation='sigmoid'))\n",
    "    # Hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(4, input_dim=16,activation='sigmoid'))\n",
    "    # Output layer\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile a model\n",
    "    model.compile(loss='hinge',                  \n",
    "                  optimizer=tf.keras.optimizers.SGD(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ranking-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3681 samples, validate on 1227 samples\n",
      "Epoch 1/500\n",
      "3681/3681 [==============================] - 0s 130us/sample - loss: 1.2900 - acc: 0.9603 - val_loss: 1.2264 - val_acc: 0.9487\n",
      "Epoch 2/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.1927 - acc: 0.9603 - val_loss: 1.1543 - val_acc: 0.9487\n",
      "Epoch 3/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.1352 - acc: 0.9603 - val_loss: 1.1119 - val_acc: 0.9487\n",
      "Epoch 4/500\n",
      "3681/3681 [==============================] - 0s 82us/sample - loss: 1.1007 - acc: 0.9603 - val_loss: 1.0858 - val_acc: 0.9487\n",
      "Epoch 5/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0788 - acc: 0.9603 - val_loss: 1.0686 - val_acc: 0.9487\n",
      "Epoch 6/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0641 - acc: 0.9603 - val_loss: 1.0567 - val_acc: 0.9487\n",
      "Epoch 7/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0537 - acc: 0.9603 - val_loss: 1.0481 - val_acc: 0.9487\n",
      "Epoch 8/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 1.0460 - acc: 0.9603 - val_loss: 1.0416 - val_acc: 0.9487\n",
      "Epoch 9/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0400 - acc: 0.9603 - val_loss: 1.0365 - val_acc: 0.9487\n",
      "Epoch 10/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0354 - acc: 0.9603 - val_loss: 1.0325 - val_acc: 0.9487\n",
      "Epoch 11/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0317 - acc: 0.9603 - val_loss: 1.0292 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0286 - acc: 0.9603 - val_loss: 1.0265 - val_acc: 0.9487\n",
      "Epoch 13/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0261 - acc: 0.9603 - val_loss: 1.0243 - val_acc: 0.9487\n",
      "Epoch 14/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0239 - acc: 0.9603 - val_loss: 1.0223 - val_acc: 0.9487\n",
      "Epoch 15/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0221 - acc: 0.9603 - val_loss: 1.0207 - val_acc: 0.9487\n",
      "Epoch 16/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0205 - acc: 0.9603 - val_loss: 1.0192 - val_acc: 0.9487\n",
      "Epoch 17/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0191 - acc: 0.9603 - val_loss: 1.0180 - val_acc: 0.9487\n",
      "Epoch 18/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0179 - acc: 0.9603 - val_loss: 1.0169 - val_acc: 0.9487\n",
      "Epoch 19/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0168 - acc: 0.9603 - val_loss: 1.0159 - val_acc: 0.9487\n",
      "Epoch 20/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0159 - acc: 0.9603 - val_loss: 1.0150 - val_acc: 0.9487\n",
      "Epoch 21/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 1.0150 - acc: 0.9603 - val_loss: 1.0142 - val_acc: 0.9487\n",
      "Epoch 22/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0142 - acc: 0.9603 - val_loss: 1.0135 - val_acc: 0.9487\n",
      "Epoch 23/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0135 - acc: 0.9603 - val_loss: 1.0128 - val_acc: 0.9487\n",
      "Epoch 24/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0129 - acc: 0.9603 - val_loss: 1.0122 - val_acc: 0.9487\n",
      "Epoch 25/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0123 - acc: 0.9603 - val_loss: 1.0117 - val_acc: 0.9487\n",
      "Epoch 26/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0118 - acc: 0.9603 - val_loss: 1.0112 - val_acc: 0.9487\n",
      "Epoch 27/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0113 - acc: 0.9603 - val_loss: 1.0107 - val_acc: 0.9487\n",
      "Epoch 28/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0108 - acc: 0.9603 - val_loss: 1.0103 - val_acc: 0.9487\n",
      "Epoch 29/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0104 - acc: 0.9603 - val_loss: 1.0099 - val_acc: 0.9487\n",
      "Epoch 30/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 1.0100 - acc: 0.9603 - val_loss: 1.0096 - val_acc: 0.9487\n",
      "Epoch 31/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0097 - acc: 0.9603 - val_loss: 1.0092 - val_acc: 0.9487\n",
      "Epoch 32/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0093 - acc: 0.9603 - val_loss: 1.0089 - val_acc: 0.9487\n",
      "Epoch 33/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0090 - acc: 0.9603 - val_loss: 1.0086 - val_acc: 0.9487\n",
      "Epoch 34/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 1.0087 - acc: 0.9603 - val_loss: 1.0083 - val_acc: 0.9487\n",
      "Epoch 35/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0084 - acc: 0.9603 - val_loss: 1.0081 - val_acc: 0.9487\n",
      "Epoch 36/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 1.0082 - acc: 0.9603 - val_loss: 1.0078 - val_acc: 0.9487\n",
      "Epoch 37/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0079 - acc: 0.9603 - val_loss: 1.0076 - val_acc: 0.9487\n",
      "Epoch 38/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0077 - acc: 0.9603 - val_loss: 1.0074 - val_acc: 0.9487\n",
      "Epoch 39/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0075 - acc: 0.9603 - val_loss: 1.0072 - val_acc: 0.9487\n",
      "Epoch 40/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0073 - acc: 0.9603 - val_loss: 1.0070 - val_acc: 0.9487\n",
      "Epoch 41/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 1.0071 - acc: 0.9603 - val_loss: 1.0068 - val_acc: 0.9487\n",
      "Epoch 42/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0069 - acc: 0.9603 - val_loss: 1.0066 - val_acc: 0.9487\n",
      "Epoch 43/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0067 - acc: 0.9603 - val_loss: 1.0064 - val_acc: 0.9487\n",
      "Epoch 44/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 1.0065 - acc: 0.9603 - val_loss: 1.0063 - val_acc: 0.9487\n",
      "Epoch 45/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0064 - acc: 0.9603 - val_loss: 1.0061 - val_acc: 0.9487\n",
      "Epoch 46/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 1.0062 - acc: 0.9603 - val_loss: 1.0060 - val_acc: 0.9487\n",
      "Epoch 47/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0061 - acc: 0.9603 - val_loss: 1.0058 - val_acc: 0.9487\n",
      "Epoch 48/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0059 - acc: 0.9603 - val_loss: 1.0057 - val_acc: 0.9487\n",
      "Epoch 49/500\n",
      "3681/3681 [==============================] - 0s 128us/sample - loss: 1.0058 - acc: 0.9603 - val_loss: 1.0056 - val_acc: 0.9487\n",
      "Epoch 50/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0057 - acc: 0.9603 - val_loss: 1.0055 - val_acc: 0.9487\n",
      "Epoch 51/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0056 - acc: 0.9603 - val_loss: 1.0053 - val_acc: 0.9487\n",
      "Epoch 52/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0054 - acc: 0.9603 - val_loss: 1.0052 - val_acc: 0.9487\n",
      "Epoch 53/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0053 - acc: 0.9603 - val_loss: 1.0051 - val_acc: 0.9487\n",
      "Epoch 54/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0052 - acc: 0.9603 - val_loss: 1.0050 - val_acc: 0.9487\n",
      "Epoch 55/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 1.0051 - acc: 0.9603 - val_loss: 1.0049 - val_acc: 0.9487\n",
      "Epoch 56/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 1.0050 - acc: 0.9603 - val_loss: 1.0048 - val_acc: 0.9487\n",
      "Epoch 57/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0049 - acc: 0.9603 - val_loss: 1.0047 - val_acc: 0.9487\n",
      "Epoch 58/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0048 - acc: 0.9603 - val_loss: 1.0046 - val_acc: 0.9487\n",
      "Epoch 59/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0047 - acc: 0.9603 - val_loss: 1.0046 - val_acc: 0.9487\n",
      "Epoch 60/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0046 - acc: 0.9603 - val_loss: 1.0045 - val_acc: 0.9487\n",
      "Epoch 61/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0046 - acc: 0.9603 - val_loss: 1.0044 - val_acc: 0.9487\n",
      "Epoch 62/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0045 - acc: 0.9603 - val_loss: 1.0043 - val_acc: 0.9487\n",
      "Epoch 63/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0044 - acc: 0.9603 - val_loss: 1.0042 - val_acc: 0.9487\n",
      "Epoch 64/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0043 - acc: 0.9603 - val_loss: 1.0042 - val_acc: 0.9487\n",
      "Epoch 65/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 1.0043 - acc: 0.9603 - val_loss: 1.0041 - val_acc: 0.9487\n",
      "Epoch 66/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0042 - acc: 0.9603 - val_loss: 1.0040 - val_acc: 0.9487\n",
      "Epoch 67/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0041 - acc: 0.9603 - val_loss: 1.0040 - val_acc: 0.9487\n",
      "Epoch 68/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0040 - acc: 0.9603 - val_loss: 1.0039 - val_acc: 0.9487\n",
      "Epoch 69/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 1.0040 - acc: 0.9603 - val_loss: 1.0038 - val_acc: 0.9487\n",
      "Epoch 70/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0039 - acc: 0.9603 - val_loss: 1.0038 - val_acc: 0.9487\n",
      "Epoch 71/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0039 - acc: 0.9603 - val_loss: 1.0037 - val_acc: 0.9487\n",
      "Epoch 72/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0038 - acc: 0.9603 - val_loss: 1.0037 - val_acc: 0.9487\n",
      "Epoch 73/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 1.0037 - acc: 0.9603 - val_loss: 1.0036 - val_acc: 0.9487\n",
      "Epoch 74/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 1.0037 - acc: 0.9603 - val_loss: 1.0036 - val_acc: 0.9487\n",
      "Epoch 75/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0036 - acc: 0.9603 - val_loss: 1.0035 - val_acc: 0.9487\n",
      "Epoch 76/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 1.0036 - acc: 0.9603 - val_loss: 1.0035 - val_acc: 0.9487\n",
      "Epoch 77/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0035 - acc: 0.9603 - val_loss: 1.0034 - val_acc: 0.9487\n",
      "Epoch 78/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0035 - acc: 0.9603 - val_loss: 1.0034 - val_acc: 0.9487\n",
      "Epoch 79/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0034 - acc: 0.9603 - val_loss: 1.0033 - val_acc: 0.9487\n",
      "Epoch 80/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 1.0034 - acc: 0.9603 - val_loss: 1.0033 - val_acc: 0.9487\n",
      "Epoch 81/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0033 - acc: 0.9603 - val_loss: 1.0032 - val_acc: 0.9487\n",
      "Epoch 82/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0033 - acc: 0.9603 - val_loss: 1.0032 - val_acc: 0.9487\n",
      "Epoch 83/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0033 - acc: 0.9603 - val_loss: 1.0031 - val_acc: 0.9487\n",
      "Epoch 84/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0032 - acc: 0.9603 - val_loss: 1.0031 - val_acc: 0.9487\n",
      "Epoch 85/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0032 - acc: 0.9603 - val_loss: 1.0031 - val_acc: 0.9487\n",
      "Epoch 86/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0031 - acc: 0.9603 - val_loss: 1.0030 - val_acc: 0.9487\n",
      "Epoch 87/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 1.0031 - acc: 0.9603 - val_loss: 1.0030 - val_acc: 0.9487\n",
      "Epoch 88/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 1.0031 - acc: 0.9603 - val_loss: 1.0030 - val_acc: 0.9487\n",
      "Epoch 89/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0030 - acc: 0.9603 - val_loss: 1.0029 - val_acc: 0.9487\n",
      "Epoch 90/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0030 - acc: 0.9603 - val_loss: 1.0029 - val_acc: 0.9487\n",
      "Epoch 91/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0030 - acc: 0.9603 - val_loss: 1.0028 - val_acc: 0.9487\n",
      "Epoch 92/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0029 - acc: 0.9603 - val_loss: 1.0028 - val_acc: 0.9487\n",
      "Epoch 93/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0029 - acc: 0.9603 - val_loss: 1.0028 - val_acc: 0.9487\n",
      "Epoch 94/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0028 - acc: 0.9603 - val_loss: 1.0028 - val_acc: 0.9487\n",
      "Epoch 95/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 1.0028 - acc: 0.9603 - val_loss: 1.0027 - val_acc: 0.9487\n",
      "Epoch 96/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0028 - acc: 0.9603 - val_loss: 1.0027 - val_acc: 0.9487\n",
      "Epoch 97/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0028 - acc: 0.9603 - val_loss: 1.0027 - val_acc: 0.9487\n",
      "Epoch 98/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0027 - acc: 0.9603 - val_loss: 1.0026 - val_acc: 0.9487\n",
      "Epoch 99/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0027 - acc: 0.9603 - val_loss: 1.0026 - val_acc: 0.9487\n",
      "Epoch 100/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 1.0027 - acc: 0.9603 - val_loss: 1.0026 - val_acc: 0.9487\n",
      "Epoch 101/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0026 - acc: 0.9603 - val_loss: 1.0025 - val_acc: 0.9487\n",
      "Epoch 102/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0026 - acc: 0.9603 - val_loss: 1.0025 - val_acc: 0.9487\n",
      "Epoch 103/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0026 - acc: 0.9603 - val_loss: 1.0025 - val_acc: 0.9487\n",
      "Epoch 104/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0026 - acc: 0.9603 - val_loss: 1.0025 - val_acc: 0.9487\n",
      "Epoch 105/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0025 - acc: 0.9603 - val_loss: 1.0024 - val_acc: 0.9487\n",
      "Epoch 106/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0025 - acc: 0.9603 - val_loss: 1.0024 - val_acc: 0.9487\n",
      "Epoch 107/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0025 - acc: 0.9603 - val_loss: 1.0024 - val_acc: 0.9487\n",
      "Epoch 108/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0025 - acc: 0.9603 - val_loss: 1.0024 - val_acc: 0.9487\n",
      "Epoch 109/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 1.0024 - acc: 0.9603 - val_loss: 1.0023 - val_acc: 0.9487\n",
      "Epoch 110/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0024 - acc: 0.9603 - val_loss: 1.0023 - val_acc: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0024 - acc: 0.9603 - val_loss: 1.0023 - val_acc: 0.9487\n",
      "Epoch 112/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0024 - acc: 0.9603 - val_loss: 1.0023 - val_acc: 0.9487\n",
      "Epoch 113/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0023 - acc: 0.9603 - val_loss: 1.0023 - val_acc: 0.9487\n",
      "Epoch 114/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0023 - acc: 0.9603 - val_loss: 1.0022 - val_acc: 0.9487\n",
      "Epoch 115/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0023 - acc: 0.9603 - val_loss: 1.0022 - val_acc: 0.9487\n",
      "Epoch 116/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0023 - acc: 0.9603 - val_loss: 1.0022 - val_acc: 0.9487\n",
      "Epoch 117/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0022 - acc: 0.9603 - val_loss: 1.0022 - val_acc: 0.9487\n",
      "Epoch 118/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0022 - acc: 0.9603 - val_loss: 1.0022 - val_acc: 0.9487\n",
      "Epoch 119/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0022 - acc: 0.9603 - val_loss: 1.0021 - val_acc: 0.9487\n",
      "Epoch 120/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0022 - acc: 0.9603 - val_loss: 1.0021 - val_acc: 0.9487\n",
      "Epoch 121/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 1.0022 - acc: 0.9603 - val_loss: 1.0021 - val_acc: 0.9487\n",
      "Epoch 122/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0021 - val_acc: 0.9487\n",
      "Epoch 123/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0021 - val_acc: 0.9487\n",
      "Epoch 124/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 125/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 126/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 127/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0021 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 128/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 129/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0020 - val_acc: 0.9487\n",
      "Epoch 130/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 131/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 132/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 133/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 1.0020 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 134/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 135/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0019 - val_acc: 0.9487\n",
      "Epoch 136/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 137/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 138/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 139/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 140/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0019 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 141/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 142/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 143/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0018 - val_acc: 0.9487\n",
      "Epoch 144/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 145/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 146/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 147/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0018 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 148/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 149/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 150/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 151/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0017 - val_acc: 0.9487\n",
      "Epoch 152/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 153/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 154/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 155/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0017 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 156/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 157/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 158/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 159/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 160/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0016 - val_acc: 0.9487\n",
      "Epoch 161/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 162/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 163/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 164/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 165/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0016 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 166/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 167/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 168/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 169/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 170/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0015 - val_acc: 0.9487\n",
      "Epoch 171/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 172/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 173/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 174/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 175/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 176/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0015 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 177/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 178/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 179/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 180/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 181/500\n",
      "3681/3681 [==============================] - 0s 91us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 182/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0014 - val_acc: 0.9487\n",
      "Epoch 183/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 184/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 185/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 186/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 187/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0014 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 189/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 190/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 191/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 192/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 193/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 194/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 195/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 196/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0013 - val_acc: 0.9487\n",
      "Epoch 197/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 198/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 199/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 200/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 201/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 202/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0013 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 203/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 204/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 205/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 206/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 207/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 208/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 209/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 210/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 211/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 212/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0012 - val_acc: 0.9487\n",
      "Epoch 213/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 214/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 215/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 216/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 217/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 218/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0012 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 219/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 220/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 221/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 222/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 223/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 224/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 225/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 226/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 228/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 229/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 230/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 231/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0011 - val_acc: 0.9487\n",
      "Epoch 232/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 233/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 234/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 235/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 236/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 237/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 238/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0011 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 239/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 240/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 241/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 242/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 243/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 244/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 245/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 246/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 247/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 248/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 249/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 250/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 251/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 252/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 253/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 254/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0010 - val_acc: 0.9487\n",
      "Epoch 255/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 256/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 257/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 258/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 259/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 260/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 261/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0010 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 262/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 263/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 264/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 265/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 266/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 267/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 268/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 269/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 270/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 271/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 272/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 273/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 274/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 275/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 276/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 277/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 278/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 279/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 280/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 281/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 282/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0009 - val_acc: 0.9487\n",
      "Epoch 283/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 284/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 285/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 286/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 287/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 288/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 289/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 290/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0009 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 291/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 292/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 293/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 294/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 295/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 296/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 297/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 298/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 299/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 300/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 301/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 302/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 303/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 304/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 305/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 306/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 307/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 308/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 309/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 310/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 311/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 312/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 313/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 314/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 315/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 316/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 317/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0008 - val_acc: 0.9487\n",
      "Epoch 318/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 319/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 320/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 321/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 322/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 323/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 324/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 325/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 326/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0008 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 327/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 328/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 329/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 330/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 331/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 332/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 333/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 334/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 335/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 336/500\n",
      "3681/3681 [==============================] - 0s 89us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 337/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 338/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 339/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 340/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 341/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 342/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 344/500\n",
      "3681/3681 [==============================] - 0s 124us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 345/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 346/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 347/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 348/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 349/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 350/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 351/500\n",
      "3681/3681 [==============================] - 0s 82us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 352/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 353/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 354/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 355/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 356/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 357/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 358/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 359/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 360/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 361/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 362/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 363/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0007 - val_acc: 0.9487\n",
      "Epoch 364/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 365/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 366/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 367/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 368/500\n",
      "3681/3681 [==============================] - 0s 94us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 369/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 370/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 371/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 372/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 373/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 374/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 1.0007 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 375/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 376/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 377/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 378/500\n",
      "3681/3681 [==============================] - 0s 91us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 379/500\n",
      "3681/3681 [==============================] - 0s 99us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 380/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 381/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 382/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 383/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 384/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 385/500\n",
      "3681/3681 [==============================] - 0s 93us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 386/500\n",
      "3681/3681 [==============================] - 0s 95us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 387/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 388/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 389/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 390/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 391/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 392/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 393/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 394/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 395/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 396/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 397/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 398/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 399/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 400/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 401/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 402/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 403/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 404/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 405/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 406/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 407/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 408/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 409/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 410/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 411/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 412/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 413/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 414/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 415/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 416/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 417/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 418/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 419/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 420/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 421/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 422/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 423/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 424/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 425/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0006 - val_acc: 0.9487\n",
      "Epoch 426/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 427/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 428/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 429/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 430/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 431/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 432/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 433/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 434/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 435/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 436/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 437/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 438/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0006 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 439/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 440/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 441/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 442/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 443/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 444/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 445/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 446/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 447/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 448/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 449/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 450/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 451/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 452/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 453/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 454/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 455/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 456/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 457/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 458/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 57us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 460/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 461/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 462/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 463/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 464/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 465/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 466/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 467/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 468/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 469/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 470/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 471/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 472/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 473/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 474/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 475/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 476/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 477/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 478/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 479/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 480/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 481/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 482/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 483/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 484/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 485/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 486/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 487/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 488/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 489/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 490/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 491/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 492/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 493/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 494/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 495/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 496/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 497/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 498/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 499/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n",
      "Epoch 500/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 1.0005 - acc: 0.9603 - val_loss: 1.0005 - val_acc: 0.9487\n"
     ]
    }
   ],
   "source": [
    "model_4 = create_model_4()\n",
    "model_4.summary()\n",
    "\n",
    "results_4 = model_4.fit(\n",
    "    x_tr, y_tr,\n",
    "    epochs= training_epochs,\n",
    "    validation_data = (x_ts, y_ts),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fiscal-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Model 4 #######################\n",
      "\n",
      "\n",
      "Evaluating on training set...\n",
      "loss=1.0005, accuracy: 96.0337%\n",
      "Evaluating on testing set...\n",
      "loss=1.0005, accuracy: 94.8655%\n",
      "\n",
      "\n",
      "########################################################\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Loss : 1.2900\n",
      "\n",
      "Minimum Loss : 1.0005\n",
      "\n",
      "Loss difference : 0.2895\n"
     ]
    }
   ],
   "source": [
    "print(\"####################### Model 4 #######################\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss_4, accuracy_4) = model_4.evaluate(x_tr, y_tr, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_4,accuracy_4 * 100))\n",
    "\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss_4, accuracy_4) = model_4.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_4,accuracy_4 * 100))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"########################################################\")\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(results_4.history['acc'])\n",
    "plt.plot(results_4.history['val_acc'])\n",
    "plt.title('model 4 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(results_4.history['loss'])\n",
    "plt.plot(results_4.history['val_loss'])\n",
    "plt.title('model 4 loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "max_loss_4 = np.max(results_4.history['loss'])\n",
    "min_loss_4 = np.min(results_4.history['loss'])\n",
    "print(\"Maximum Loss : {:.4f}\".format(max_loss_4))\n",
    "print(\"\")\n",
    "print(\"Minimum Loss : {:.4f}\".format(min_loss_4))\n",
    "print(\"\")\n",
    "print(\"Loss difference : {:.4f}\".format((max_loss_4 - min_loss_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-casting",
   "metadata": {},
   "source": [
    "## Exportar modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-soldier",
   "metadata": {},
   "source": [
    "Exportamos los modelos correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bacterial-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(\"models/my_model_1.h5\", save_format='h5')\n",
    "model_2.save(\"models/my_model_2.h5\", save_format='h5')\n",
    "model_3.save(\"models/my_model_3.h5\", save_format='h5')\n",
    "model_4.save(\"models/my_model_4.h5\", save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-duncan",
   "metadata": {},
   "source": [
    "Importamos y verificamos que el modelo se cargo correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "diagnostic-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_imported = tf.keras.models.load_model('models/my_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cutting-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3681 samples, validate on 1227 samples\n",
      "Epoch 1/500\n",
      "3681/3681 [==============================] - 1s 142us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 2/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 3/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 4/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1690 - val_acc: 0.9487\n",
      "Epoch 5/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 6/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1689 - val_acc: 0.9487\n",
      "Epoch 7/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1419 - acc: 0.9603 - val_loss: 0.1683 - val_acc: 0.9487\n",
      "Epoch 8/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 9/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 10/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1418 - acc: 0.9603 - val_loss: 0.1681 - val_acc: 0.9487\n",
      "Epoch 11/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1417 - acc: 0.9603 - val_loss: 0.1682 - val_acc: 0.9487\n",
      "Epoch 12/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1417 - acc: 0.9603 - val_loss: 0.1682 - val_acc: 0.9487\n",
      "Epoch 13/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1417 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 14/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1416 - acc: 0.9603 - val_loss: 0.1685 - val_acc: 0.9487\n",
      "Epoch 15/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1416 - acc: 0.9603 - val_loss: 0.1685 - val_acc: 0.9487\n",
      "Epoch 16/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1416 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 17/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1416 - acc: 0.9603 - val_loss: 0.1685 - val_acc: 0.9487\n",
      "Epoch 18/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 19/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1685 - val_acc: 0.9487\n",
      "Epoch 20/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 21/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 22/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 23/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1415 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 24/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1414 - acc: 0.9603 - val_loss: 0.1683 - val_acc: 0.9487\n",
      "Epoch 25/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1414 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 26/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1414 - acc: 0.9603 - val_loss: 0.1683 - val_acc: 0.9487\n",
      "Epoch 27/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1414 - acc: 0.9603 - val_loss: 0.1684 - val_acc: 0.9487\n",
      "Epoch 28/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1413 - acc: 0.9603 - val_loss: 0.1683 - val_acc: 0.9487\n",
      "Epoch 29/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1413 - acc: 0.9603 - val_loss: 0.1681 - val_acc: 0.9487\n",
      "Epoch 30/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1413 - acc: 0.9603 - val_loss: 0.1681 - val_acc: 0.9487\n",
      "Epoch 31/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1413 - acc: 0.9603 - val_loss: 0.1682 - val_acc: 0.9487\n",
      "Epoch 32/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1413 - acc: 0.9603 - val_loss: 0.1681 - val_acc: 0.9487\n",
      "Epoch 33/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1682 - val_acc: 0.9487\n",
      "Epoch 34/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1680 - val_acc: 0.9487\n",
      "Epoch 35/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1680 - val_acc: 0.9487\n",
      "Epoch 36/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 37/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1412 - acc: 0.9603 - val_loss: 0.1680 - val_acc: 0.9487\n",
      "Epoch 38/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1411 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 39/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1411 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 40/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1411 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 41/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1411 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9487\n",
      "Epoch 42/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 43/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1411 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9487\n",
      "Epoch 44/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1679 - val_acc: 0.9487\n",
      "Epoch 45/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9487\n",
      "Epoch 46/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 47/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 48/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1410 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 49/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1678 - val_acc: 0.9487\n",
      "Epoch 50/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 51/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1677 - val_acc: 0.9487\n",
      "Epoch 52/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1676 - val_acc: 0.9487\n",
      "Epoch 53/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1409 - acc: 0.9603 - val_loss: 0.1675 - val_acc: 0.9487\n",
      "Epoch 54/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1408 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 55/500\n",
      "3681/3681 [==============================] - 0s 89us/sample - loss: 0.1408 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 56/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1408 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 57/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1408 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 58/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1408 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 59/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 60/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 61/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1674 - val_acc: 0.9487\n",
      "Epoch 62/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 63/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1407 - acc: 0.9603 - val_loss: 0.1672 - val_acc: 0.9487\n",
      "Epoch 64/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 65/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1672 - val_acc: 0.9487\n",
      "Epoch 66/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 67/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1673 - val_acc: 0.9487\n",
      "Epoch 68/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1672 - val_acc: 0.9487\n",
      "Epoch 69/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 70/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1406 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 71/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 72/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 73/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1671 - val_acc: 0.9487\n",
      "Epoch 74/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1670 - val_acc: 0.9487\n",
      "Epoch 75/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1405 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 76/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1404 - acc: 0.9603 - val_loss: 0.1669 - val_acc: 0.9487\n",
      "Epoch 77/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1404 - acc: 0.9603 - val_loss: 0.1669 - val_acc: 0.9487\n",
      "Epoch 78/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1404 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 79/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1404 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 80/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1404 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 81/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1667 - val_acc: 0.9487\n",
      "Epoch 82/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 83/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 84/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 85/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1668 - val_acc: 0.9487\n",
      "Epoch 86/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1403 - acc: 0.9603 - val_loss: 0.1667 - val_acc: 0.9487\n",
      "Epoch 87/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1666 - val_acc: 0.9487\n",
      "Epoch 88/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1666 - val_acc: 0.9487\n",
      "Epoch 89/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1666 - val_acc: 0.9487\n",
      "Epoch 90/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1666 - val_acc: 0.9487\n",
      "Epoch 91/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 92/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 93/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1402 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 94/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 95/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 96/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 97/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 98/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1664 - val_acc: 0.9487\n",
      "Epoch 99/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1401 - acc: 0.9603 - val_loss: 0.1665 - val_acc: 0.9487\n",
      "Epoch 100/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1664 - val_acc: 0.9487\n",
      "Epoch 101/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1663 - val_acc: 0.9487\n",
      "Epoch 102/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1663 - val_acc: 0.9487\n",
      "Epoch 103/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1663 - val_acc: 0.9487\n",
      "Epoch 104/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1400 - acc: 0.9603 - val_loss: 0.1663 - val_acc: 0.9487\n",
      "Epoch 105/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.9487\n",
      "Epoch 106/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1661 - val_acc: 0.9487\n",
      "Epoch 107/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 108/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 109/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 110/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 111/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 112/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1399 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 113/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1398 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 114/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1398 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 115/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1398 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 116/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1398 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 117/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 119/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 120/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 121/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 122/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1397 - acc: 0.9603 - val_loss: 0.1658 - val_acc: 0.9487\n",
      "Epoch 123/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 124/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 125/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 126/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 127/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 128/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 129/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1396 - acc: 0.9603 - val_loss: 0.1657 - val_acc: 0.9487\n",
      "Epoch 130/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 131/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 132/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 133/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1656 - val_acc: 0.9487\n",
      "Epoch 134/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 135/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1655 - val_acc: 0.9487\n",
      "Epoch 136/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1395 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 137/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 138/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 139/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 140/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 141/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 142/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 143/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 144/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1393 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 145/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1394 - acc: 0.9603 - val_loss: 0.1654 - val_acc: 0.9487\n",
      "Epoch 146/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1393 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 147/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1393 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 148/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1393 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 149/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1393 - acc: 0.9603 - val_loss: 0.1652 - val_acc: 0.9487\n",
      "Epoch 150/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 151/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 152/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 153/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 154/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 155/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1651 - val_acc: 0.9487\n",
      "Epoch 156/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1653 - val_acc: 0.9487\n",
      "Epoch 157/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1650 - val_acc: 0.9487\n",
      "Epoch 158/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1391 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 159/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 160/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1391 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 161/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1391 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 162/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1391 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 163/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.1391 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 164/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 165/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 166/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1647 - val_acc: 0.9487\n",
      "Epoch 167/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 168/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 169/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1648 - val_acc: 0.9487\n",
      "Epoch 170/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 171/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1646 - val_acc: 0.9487\n",
      "Epoch 172/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 173/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1390 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 174/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 175/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 176/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 177/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 178/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 179/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 180/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1389 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 181/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 182/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 183/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1645 - val_acc: 0.9487\n",
      "Epoch 184/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 185/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 186/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 187/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1644 - val_acc: 0.9487\n",
      "Epoch 188/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1387 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 189/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 190/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 191/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1387 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 192/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1388 - acc: 0.9603 - val_loss: 0.1635 - val_acc: 0.9487\n",
      "Epoch 193/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1387 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 194/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1387 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 195/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 196/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 197/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 198/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 199/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 200/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 201/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 202/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 203/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 204/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1386 - acc: 0.9603 - val_loss: 0.1642 - val_acc: 0.9487\n",
      "Epoch 205/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 206/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1643 - val_acc: 0.9487\n",
      "Epoch 207/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 208/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 209/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 210/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 211/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 212/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 213/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 214/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1385 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 215/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 216/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 217/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 218/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 219/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1384 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 220/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 221/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 222/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 223/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 224/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 225/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 226/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1640 - val_acc: 0.9487\n",
      "Epoch 227/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1639 - val_acc: 0.9487\n",
      "Epoch 228/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 229/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1383 - acc: 0.9603 - val_loss: 0.1638 - val_acc: 0.9487\n",
      "Epoch 230/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 231/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 232/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 233/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1637 - val_acc: 0.9487\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1636 - val_acc: 0.9487\n",
      "Epoch 235/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 236/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 237/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 238/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 239/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 240/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1382 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 241/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 242/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 243/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 244/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 245/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 246/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 247/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 248/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1381 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 249/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 250/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 251/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 252/500\n",
      "3681/3681 [==============================] - 0s 78us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 253/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 254/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 255/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1380 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 256/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 257/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 258/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 259/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1634 - val_acc: 0.9487\n",
      "Epoch 260/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 261/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 262/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 263/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1379 - acc: 0.9603 - val_loss: 0.1633 - val_acc: 0.9487\n",
      "Epoch 264/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 265/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 266/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 267/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 268/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 269/500\n",
      "3681/3681 [==============================] - ETA: 0s - loss: 0.1372 - acc: 0.960 - 0s 54us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 270/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 271/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 272/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 273/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1632 - val_acc: 0.9487\n",
      "Epoch 274/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1378 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 275/500\n",
      "3681/3681 [==============================] - 0s 96us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 276/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1631 - val_acc: 0.9487\n",
      "Epoch 277/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 278/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1630 - val_acc: 0.9487\n",
      "Epoch 279/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 280/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 281/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1377 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 282/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 283/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 284/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 285/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1629 - val_acc: 0.9487\n",
      "Epoch 286/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 287/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 288/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 289/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 290/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 291/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 292/500\n",
      "3681/3681 [==============================] - 0s 75us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1628 - val_acc: 0.9487\n",
      "Epoch 293/500\n",
      "3681/3681 [==============================] - 0s 74us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 294/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 295/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1376 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 296/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 297/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 298/500\n",
      "3681/3681 [==============================] - 0s 87us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 299/500\n",
      "3681/3681 [==============================] - 0s 69us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 300/500\n",
      "3681/3681 [==============================] - 0s 58us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 301/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 302/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 303/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1375 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 304/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 305/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 306/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 307/500\n",
      "3681/3681 [==============================] - 0s 59us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 308/500\n",
      "3681/3681 [==============================] - 0s 67us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 309/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 310/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 311/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 312/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1374 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 313/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 314/500\n",
      "3681/3681 [==============================] - 0s 72us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 315/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 316/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 317/500\n",
      "3681/3681 [==============================] - 0s 56us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 318/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 319/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 320/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1626 - val_acc: 0.9487\n",
      "Epoch 321/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1627 - val_acc: 0.9487\n",
      "Epoch 322/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 323/500\n",
      "3681/3681 [==============================] - 0s 70us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 324/500\n",
      "3681/3681 [==============================] - 0s 73us/sample - loss: 0.1373 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 325/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 326/500\n",
      "3681/3681 [==============================] - 0s 76us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1625 - val_acc: 0.9487\n",
      "Epoch 327/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 328/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 329/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 330/500\n",
      "3681/3681 [==============================] - 0s 68us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 331/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 332/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 333/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 334/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 335/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 336/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1624 - val_acc: 0.9487\n",
      "Epoch 337/500\n",
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 338/500\n",
      "3681/3681 [==============================] - 0s 102us/sample - loss: 0.1372 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 339/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 340/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1623 - val_acc: 0.9487\n",
      "Epoch 341/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 342/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 343/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 344/500\n",
      "3681/3681 [==============================] - 0s 91us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 345/500\n",
      "3681/3681 [==============================] - ETA: 0s - loss: 0.1380 - acc: 0.960 - 1s 140us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 346/500\n",
      "3681/3681 [==============================] - 0s 105us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 347/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 348/500\n",
      "3681/3681 [==============================] - 0s 71us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 349/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 350/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 80us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1622 - val_acc: 0.9487\n",
      "Epoch 351/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 352/500\n",
      "3681/3681 [==============================] - 0s 101us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 353/500\n",
      "3681/3681 [==============================] - 0s 88us/sample - loss: 0.1371 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 354/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 355/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 356/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 357/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 358/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1370 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 359/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 360/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 361/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 362/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 363/500\n",
      "3681/3681 [==============================] - 0s 65us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 364/500\n",
      "3681/3681 [==============================] - 0s 57us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 365/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 366/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 367/500\n",
      "3681/3681 [==============================] - 0s 55us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 368/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 369/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1621 - val_acc: 0.9487\n",
      "Epoch 370/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 371/500\n",
      "3681/3681 [==============================] - 0s 62us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 372/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1620 - val_acc: 0.9487\n",
      "Epoch 373/500\n",
      "3681/3681 [==============================] - 0s 86us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1619 - val_acc: 0.9487\n",
      "Epoch 374/500\n",
      "3681/3681 [==============================] - 0s 81us/sample - loss: 0.1369 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 375/500\n",
      "3681/3681 [==============================] - 0s 83us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 376/500\n",
      "3681/3681 [==============================] - 0s 112us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 377/500\n",
      "3681/3681 [==============================] - 0s 66us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 378/500\n",
      "3681/3681 [==============================] - 0s 85us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 379/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 380/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 381/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 382/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 383/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 384/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1368 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 385/500\n",
      "3681/3681 [==============================] - 0s 79us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 386/500\n",
      "3681/3681 [==============================] - 0s 77us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1618 - val_acc: 0.9487\n",
      "Epoch 387/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 388/500\n",
      "3681/3681 [==============================] - 0s 60us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 389/500\n",
      "3681/3681 [==============================] - 0s 61us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 390/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 391/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1617 - val_acc: 0.9487\n",
      "Epoch 392/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 393/500\n",
      "3681/3681 [==============================] - 0s 54us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 394/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 395/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1367 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 396/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 397/500\n",
      "3681/3681 [==============================] - 0s 63us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 398/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 399/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1614 - val_acc: 0.9487\n",
      "Epoch 400/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 401/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 402/500\n",
      "3681/3681 [==============================] - 0s 52us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1616 - val_acc: 0.9487\n",
      "Epoch 403/500\n",
      "3681/3681 [==============================] - 0s 51us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1614 - val_acc: 0.9487\n",
      "Epoch 404/500\n",
      "3681/3681 [==============================] - 0s 64us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 405/500\n",
      "3681/3681 [==============================] - 0s 47us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 406/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 407/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 408/500\n",
      "3681/3681 [==============================] - 0s 50us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 409/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1366 - acc: 0.9603 - val_loss: 0.1615 - val_acc: 0.9487\n",
      "Epoch 410/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 411/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 412/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 413/500\n",
      "3681/3681 [==============================] - 0s 53us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 414/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 415/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 416/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 417/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 418/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 419/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 420/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 421/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 422/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 423/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1365 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 424/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 425/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 426/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 427/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 428/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 429/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 430/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 431/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 432/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1364 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 433/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 434/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 435/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 436/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 437/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 438/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 439/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1613 - val_acc: 0.9487\n",
      "Epoch 440/500\n",
      "3681/3681 [==============================] - 0s 46us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 441/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1612 - val_acc: 0.9487\n",
      "Epoch 442/500\n",
      "3681/3681 [==============================] - 0s 49us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 443/500\n",
      "3681/3681 [==============================] - 0s 48us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 444/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 445/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 446/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 447/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1611 - val_acc: 0.9487\n",
      "Epoch 448/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1610 - val_acc: 0.9487\n",
      "Epoch 449/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1610 - val_acc: 0.9487\n",
      "Epoch 450/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1610 - val_acc: 0.9487\n",
      "Epoch 451/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 452/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1610 - val_acc: 0.9487\n",
      "Epoch 453/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 454/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1363 - acc: 0.9603 - val_loss: 0.1603 - val_acc: 0.9487\n",
      "Epoch 455/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1605 - val_acc: 0.9487\n",
      "Epoch 456/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 457/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 458/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 459/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 460/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1610 - val_acc: 0.9487\n",
      "Epoch 461/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1603 - val_acc: 0.9487\n",
      "Epoch 462/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1362 - acc: 0.9603 - val_loss: 0.1604 - val_acc: 0.9487\n",
      "Epoch 463/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1605 - val_acc: 0.9487\n",
      "Epoch 464/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 465/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 467/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 468/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 469/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1609 - val_acc: 0.9487\n",
      "Epoch 470/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 471/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 472/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 473/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 474/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 475/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 476/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1361 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 477/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 478/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 479/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 480/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 481/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 482/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 483/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 484/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 485/500\n",
      "3681/3681 [==============================] - 0s 44us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 486/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 487/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 488/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 489/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 490/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 491/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1606 - val_acc: 0.9487\n",
      "Epoch 492/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1360 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 493/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1608 - val_acc: 0.9487\n",
      "Epoch 494/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 495/500\n",
      "3681/3681 [==============================] - 0s 43us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 496/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1607 - val_acc: 0.9487\n",
      "Epoch 497/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1602 - val_acc: 0.9487\n",
      "Epoch 498/500\n",
      "3681/3681 [==============================] - 0s 41us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1603 - val_acc: 0.9487\n",
      "Epoch 499/500\n",
      "3681/3681 [==============================] - 0s 42us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1604 - val_acc: 0.9487\n",
      "Epoch 500/500\n",
      "3681/3681 [==============================] - 0s 45us/sample - loss: 0.1359 - acc: 0.9603 - val_loss: 0.1604 - val_acc: 0.9487\n"
     ]
    }
   ],
   "source": [
    "results_1_imported = model_1_imported.fit(\n",
    "    x_tr, y_tr,\n",
    "    epochs= training_epochs,\n",
    "    validation_data = (x_ts, y_ts),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "recreational-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################### Model 1 #######################\n",
      "Evaluating on training set...\n",
      "loss=0.1358, accuracy: 96.0337%\n",
      "Evaluating on testing set...\n",
      "loss=0.1604, accuracy: 94.8655%\n"
     ]
    }
   ],
   "source": [
    "print(\"####################### Model 1 #######################\")\n",
    "print(\"Evaluating on training set...\")\n",
    "(loss_1_imported, accuracy_1_imported) = model_1_imported.evaluate(x_tr, y_tr, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_1_imported,accuracy_1_imported * 100))\n",
    "\n",
    "print(\"Evaluating on testing set...\")\n",
    "(loss_1_imported, accuracy_1_imported) = model_1_imported.evaluate(x_ts, y_ts, verbose=0)\n",
    "print(\"loss={:.4f}, accuracy: {:.4f}%\".format(loss_1_imported, accuracy_1_imported * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-relative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
